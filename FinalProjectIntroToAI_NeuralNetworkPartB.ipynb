{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52ce080d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip data\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "if not os.path.exists(\"data\"):\n",
    "    with zipfile.ZipFile(\"data.zip\", \"r\") as zip_ref:\n",
    "        zip_ref.extractall(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1efaf3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "NUM_EPOCHS = 5\n",
    "NUM_TRAINING = 1000\n",
    "NUM_TESTING = 500\n",
    "NUM_VALIDATION = 500\n",
    "\n",
    "NUM_FACE_TRAINING = 451\n",
    "NUM_FACE_VALIDATION = 301\n",
    "NUM_FACE_TESTING = 150\n",
    "\n",
    "IMAGE_HEIGHT = 28\n",
    "IMAGE_WIDTH = 28\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae6c81b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepaths\n",
    "train_data_file = \"data/digitdata/trainingimages\"\n",
    "train_label_file = \"data/digitdata/traininglabels\"\n",
    "val_data_file = \"data/digitdata/validationimages\"\n",
    "val_label_file = \"data/digitdata/validationlabels\"\n",
    "test_data_file = \"data/digitdata/testimages\"\n",
    "test_label_file = \"data/digitdata/testlabels\"\n",
    "\n",
    "face_train_data_file = \"data/facedata/facedatatrain\"\n",
    "face_train_label_file = \"data/facedata/facedatatrainlabels\"\n",
    "face_val_data_file   = \"data/facedata/facedatavalidation\"\n",
    "face_val_label_file  = \"data/facedata/facedatavalidationlabels\"\n",
    "face_test_data_file  = \"data/facedata/facedatatest\"\n",
    "face_test_label_file = \"data/facedata/facedatatestlabels\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e1f45af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "\n",
    "#for graphing results\n",
    "import pandas as pd\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53324bb2",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fca12b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_data_file(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    return [line.rstrip(\"\\n\") for line in lines]\n",
    "\n",
    "def extract_features(raw_data):\n",
    "    features = []\n",
    "    for i in range(0, len(raw_data), 28):\n",
    "        image = raw_data[i:i+28]\n",
    "        feature = [1 if ch != ' ' else 0 for row in image for ch in row]\n",
    "        features.append(feature)\n",
    "    return features\n",
    "\n",
    "\n",
    "def read_labels(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    return [int(line.strip()) for line in lines]\n",
    "\n",
    "def load_dataset(data_file, label_file, size=None):\n",
    "    raw_data = read_data_file(data_file)\n",
    "    raw_labels = read_labels(label_file)\n",
    "\n",
    "    features = extract_features(raw_data)\n",
    "    if size is not None:\n",
    "        combined = list(zip(features, raw_labels))\n",
    "        random.shuffle(combined)\n",
    "        features, raw_labels = zip(*combined[:size])\n",
    "\n",
    "    return list(features), list(raw_labels)\n",
    "\n",
    "def one_hot_encode(y, num_classes=10):\n",
    "    encoded = np.zeros((num_classes, len(y)))\n",
    "    for idx, val in enumerate(y):\n",
    "        encoded[val][idx] = 1\n",
    "    return encoded\n",
    "\n",
    "def evaluate(predictions, labels):\n",
    "    correct = sum(p == t for p, t in zip(predictions, labels))\n",
    "    return correct / len(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99491bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_face_features(raw_data):\n",
    "    features = []\n",
    "    for i in range(0, len(raw_data), 70):  # 70 rows per image\n",
    "        image = raw_data[i:i+70]\n",
    "        assert all(len(row) == 60 for row in image), \"Expected 60 columns per row in face image\"\n",
    "        feature = [1 if ch != ' ' else 0 for row in image for ch in row]\n",
    "        features.append(feature)\n",
    "    return features\n",
    "\n",
    "def load_face_dataset(data_file, label_file, size=None):\n",
    "    raw_data = read_data_file(data_file)\n",
    "    raw_labels = read_labels(label_file)\n",
    "\n",
    "    features = extract_face_features(raw_data)\n",
    "    if size is not None:\n",
    "        combined = list(zip(features, raw_labels))\n",
    "        random.shuffle(combined)\n",
    "        features, raw_labels = zip(*combined[:size])\n",
    "\n",
    "    return list(features), list(raw_labels)\n",
    "\n",
    "def one_hot_encode_face(y, num_classes=2):\n",
    "    encoded = np.zeros((num_classes, len(y)))\n",
    "    for idx, val in enumerate(y):\n",
    "        encoded[val][idx] = 1\n",
    "    return encoded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3113e73",
   "metadata": {},
   "source": [
    "## Neural Network Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d869892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Activation functions\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def relu_derivative(z):\n",
    "    return (z > 0).astype(float)\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def sigmoid_derivative(a):\n",
    "    return a * (1 - a)\n",
    "\n",
    "def softmax(Z):\n",
    "    e_Z = np.exp(Z - np.max(Z, axis=0, keepdims=True))\n",
    "    return e_Z / np.sum(e_Z, axis=0, keepdims=True)\n",
    "\n",
    "\n",
    "# Initialize weights and biases\n",
    "def initialize_parameters(input_size, hidden1_size, hidden2_size, output_size):\n",
    "    np.random.seed(42)\n",
    "    return {\n",
    "        'W1': np.random.randn(hidden1_size, input_size) * 0.01,\n",
    "        'b1': np.zeros((hidden1_size, 1)),\n",
    "        'W2': np.random.randn(hidden2_size, hidden1_size) * 0.01,\n",
    "        'b2': np.zeros((hidden2_size, 1)),\n",
    "        'W3': np.random.randn(output_size, hidden2_size) * 0.01,\n",
    "        'b3': np.zeros((output_size, 1))\n",
    "    }\n",
    "\n",
    "# Forward pass\n",
    "def forward_propagation(X, parameters):\n",
    "    W1, b1 = parameters['W1'], parameters['b1']\n",
    "    W2, b2 = parameters['W2'], parameters['b2']\n",
    "    W3, b3 = parameters['W3'], parameters['b3']\n",
    "\n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = relu(Z1)\n",
    "\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = relu(Z2)\n",
    "\n",
    "    Z3 = np.dot(W3, A2) + b3\n",
    "    A3 = sigmoid(Z3)\n",
    "\n",
    "    cache = (Z1, A1, Z2, A2, Z3, A3)\n",
    "    return A3, cache\n",
    "\n",
    "\n",
    "def forward_propagation_face(X, parameters, dropout_rate=0.5, training=True):\n",
    "    W1, b1 = parameters['W1'], parameters['b1']\n",
    "    W2, b2 = parameters['W2'], parameters['b2']\n",
    "    W3, b3 = parameters['W3'], parameters['b3']\n",
    "\n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = relu(Z1)\n",
    "\n",
    "    if training:\n",
    "        D1 = (np.random.rand(*A1.shape) < dropout_rate).astype(float)\n",
    "        A1 *= D1\n",
    "        A1 /= dropout_rate\n",
    "    else:\n",
    "        D1 = None\n",
    "\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = relu(Z2)\n",
    "\n",
    "    if training:\n",
    "        D2 = (np.random.rand(*A2.shape) < dropout_rate).astype(float)\n",
    "        A2 *= D2\n",
    "        A2 /= dropout_rate\n",
    "    else:\n",
    "        D2 = None\n",
    "\n",
    "    Z3 = np.dot(W3, A2) + b3\n",
    "    A3 = softmax(Z3)\n",
    "\n",
    "    # Include dropout masks in the cache\n",
    "    cache = (Z1, A1, D1, Z2, A2, D2, Z3, A3)\n",
    "    return A3, cache\n",
    "\n",
    "\n",
    "\n",
    "# Loss\n",
    "def compute_loss(Y_hat, Y):\n",
    "    m = Y.shape[1]\n",
    "    return -np.sum(Y * np.log(Y_hat + 1e-8) + (1 - Y) * np.log(1 - Y_hat + 1e-8)) / m\n",
    "\n",
    "def compute_loss_l2(Y_hat, Y, parameters, lambda_reg=0.1):\n",
    "    m = Y.shape[1]\n",
    "    cross_entropy = -np.sum(Y * np.log(Y_hat + 1e-8)) / m\n",
    "    l2 = (lambda_reg / (2 * m)) * (\n",
    "        np.sum(np.square(parameters['W1'])) +\n",
    "        np.sum(np.square(parameters['W2'])) +\n",
    "        np.sum(np.square(parameters['W3']))\n",
    "    )\n",
    "    return cross_entropy + l2\n",
    "\n",
    "# Backward pass\n",
    "def backward_propagation(X, Y, parameters, cache):\n",
    "    m = X.shape[1]\n",
    "    W2, W3 = parameters['W2'], parameters['W3']\n",
    "    Z1, A1, Z2, A2, Z3, A3 = cache\n",
    "\n",
    "    dZ3 = A3 - Y\n",
    "    dW3 = (1/m) * np.dot(dZ3, A2.T)\n",
    "    db3 = (1/m) * np.sum(dZ3, axis=1, keepdims=True)\n",
    "\n",
    "    dA2 = np.dot(W3.T, dZ3)\n",
    "    dZ2 = dA2 * relu_derivative(Z2)\n",
    "    dW2 = (1/m) * np.dot(dZ2, A1.T)\n",
    "    db2 = (1/m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "\n",
    "    dA1 = np.dot(W2.T, dZ2)\n",
    "    dZ1 = dA1 * relu_derivative(Z1)\n",
    "    dW1 = (1/m) * np.dot(dZ1, X.T)\n",
    "    db1 = (1/m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "\n",
    "    return {\n",
    "        'dW1': dW1, 'db1': db1,\n",
    "        'dW2': dW2, 'db2': db2,\n",
    "        'dW3': dW3, 'db3': db3\n",
    "    }\n",
    "\n",
    "\n",
    "def backward_propagation_face(X, Y, parameters, cache, dropout_rate=0.5):\n",
    "    m = X.shape[1]\n",
    "    W2, W3 = parameters['W2'], parameters['W3']\n",
    "    Z1, A1, D1, Z2, A2, D2, Z3, A3 = cache\n",
    "\n",
    "    dZ3 = A3 - Y\n",
    "    dW3 = (1/m) * np.dot(dZ3, A2.T)\n",
    "    db3 = (1/m) * np.sum(dZ3, axis=1, keepdims=True)\n",
    "\n",
    "    dA2 = np.dot(W3.T, dZ3)\n",
    "    dA2 *= D2\n",
    "    dA2 /= dropout_rate\n",
    "    dZ2 = dA2 * relu_derivative(Z2)\n",
    "    dW2 = (1/m) * np.dot(dZ2, A1.T)\n",
    "    db2 = (1/m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "\n",
    "    dA1 = np.dot(W2.T, dZ2)\n",
    "    dA1 *= D1\n",
    "    dA1 /= dropout_rate\n",
    "    dZ1 = dA1 * relu_derivative(Z1)\n",
    "    dW1 = (1/m) * np.dot(dZ1, X.T)\n",
    "    db1 = (1/m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "\n",
    "    return {\n",
    "        'dW1': dW1, 'db1': db1,\n",
    "        'dW2': dW2, 'db2': db2,\n",
    "        'dW3': dW3, 'db3': db3\n",
    "    }\n",
    "\n",
    "# Gradient descent update\n",
    "def update_parameters(params, grads, lr):\n",
    "    for key in params:\n",
    "        params[key] -= lr * grads['d' + key]\n",
    "    return params\n",
    "\n",
    "# Prediction\n",
    "def predict_nn(X, parameters):\n",
    "    Y_hat, _ = forward_propagation(X, parameters)\n",
    "    return np.argmax(Y_hat, axis=0)\n",
    "\n",
    "def predict_nn_face(X, parameters):\n",
    "    Y_hat, _ = forward_propagation_face(X, parameters, training=False)\n",
    "    return np.argmax(Y_hat, axis=0)\n",
    "\n",
    "# Training loop\n",
    "def train_neural_net(X_train, y_train, X_test, y_test,\n",
    "                     input_size, h1, h2, output_size,\n",
    "                     epochs=1000, lr=0.1, print_loss=True,\n",
    "                     X_val=None, y_val=None, early_stopping=False, patience=10):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    parameters = initialize_parameters(input_size, h1, h2, output_size)\n",
    "    best_params = None\n",
    "    best_val_acc = 0\n",
    "    val_acc_counter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Forward and backpropagation\n",
    "        Y_hat, cache = forward_propagation(X_train, parameters)\n",
    "        loss = compute_loss(Y_hat, y_train)\n",
    "        grads = backward_propagation(X_train, y_train, parameters, cache)\n",
    "        parameters = update_parameters(parameters, grads, lr)\n",
    "\n",
    "        # Check performance every 100 epochs\n",
    "        if epoch % 100 == 0 or epoch == epochs - 1:\n",
    "            train_preds = predict_nn(X_train, parameters)\n",
    "            train_acc = evaluate(train_preds, np.argmax(y_train, axis=0))\n",
    "            \n",
    "            if X_val is not None and y_val is not None:\n",
    "                val_preds = predict_nn(X_val, parameters)\n",
    "                val_acc = evaluate(val_preds, np.argmax(y_val, axis=0))\n",
    "\n",
    "                if print_loss:\n",
    "                    print(f\"Epoch {epoch}: Loss = {loss:.4f} | Train Acc = {train_acc:.4f} | Val Acc = {val_acc:.4f}\")\n",
    "\n",
    "                # Save best model\n",
    "                if val_acc > best_val_acc:\n",
    "                    best_val_acc = val_acc\n",
    "                    best_params = {k: v.copy() for k, v in parameters.items()}\n",
    "                    val_acc_counter = 0\n",
    "                else:\n",
    "                    val_acc_counter += 1\n",
    "                    if early_stopping and val_acc_counter >= patience:\n",
    "                        print(\"Early stopping triggered.\")\n",
    "                        break\n",
    "            else:\n",
    "                if print_loss:\n",
    "                    print(f\"Epoch {epoch}: Loss = {loss:.4f} | Train Acc = {train_acc:.4f}\")\n",
    "                    \n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time  \n",
    "\n",
    "    final_params = best_params if best_params is not None else parameters\n",
    "\n",
    "    # Final test evaluation\n",
    "    test_preds = predict_nn(X_test, final_params)\n",
    "    test_acc = evaluate(test_preds, np.argmax(y_test, axis=0))\n",
    "    print(f\"Final Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "    \n",
    "    return final_params, training_time\n",
    "\n",
    "\n",
    "\n",
    "def train_neural_net_face(X_train, y_train, X_test, y_test,\n",
    "                     input_size, h1, h2, output_size,\n",
    "                     epochs=1000, lr=0.1, print_loss=True,\n",
    "                     X_val=None, y_val=None, early_stopping=False,\n",
    "                     patience=10, dropout_rate=0.5, lambda_reg=0.1):  \n",
    "    start_time = time.time()\n",
    "    \n",
    "    parameters = initialize_parameters(input_size, h1, h2, output_size)\n",
    "    best_params = None\n",
    "    best_val_acc = 0\n",
    "    val_acc_counter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # === DROPOUT + L2 ===\n",
    "        Y_hat, cache = forward_propagation_face(X_train, parameters, dropout_rate=dropout_rate, training=True)\n",
    "        loss = compute_loss_l2(Y_hat, y_train, parameters, lambda_reg=lambda_reg)\n",
    "        grads = backward_propagation_face(X_train, y_train, parameters, cache, dropout_rate=dropout_rate)\n",
    "        parameters = update_parameters(parameters, grads, lr)\n",
    "\n",
    "        if epoch % 100 == 0 or epoch == epochs - 1:\n",
    "            train_preds = predict_nn_face(X_train, parameters)\n",
    "            train_acc = evaluate(train_preds, np.argmax(y_train, axis=0))\n",
    "\n",
    "            if X_val is not None and y_val is not None:\n",
    "                val_preds = predict_nn_face(X_val, parameters)\n",
    "                val_acc = evaluate(val_preds, np.argmax(y_val, axis=0))\n",
    "\n",
    "                if print_loss:\n",
    "                    print(f\"Epoch {epoch}: Loss = {loss:.4f} | Train Acc = {train_acc:.4f} | Val Acc = {val_acc:.4f}\")\n",
    "\n",
    "                if val_acc > best_val_acc:\n",
    "                    best_val_acc = val_acc\n",
    "                    best_params = {k: v.copy() for k, v in parameters.items()}\n",
    "                    val_acc_counter = 0\n",
    "                else:\n",
    "                    val_acc_counter += 1\n",
    "                    if early_stopping and val_acc_counter >= patience:\n",
    "                        print(\"Early stopping triggered.\")\n",
    "                        break\n",
    "            else:\n",
    "                if print_loss:\n",
    "                    print(f\"Epoch {epoch}: Loss = {loss:.4f} | Train Acc = {train_acc:.4f}\")\n",
    "                    \n",
    "    end_time = time.time()  \n",
    "    training_time = end_time - start_time  \n",
    "\n",
    "    final_params = best_params if best_params is not None else parameters\n",
    "    test_preds = predict_nn_face(X_test, final_params)\n",
    "    test_acc = evaluate(test_preds, np.argmax(y_test, axis=0))\n",
    "    print(f\"Final Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"Training Time: {training_time:.2f} seconds\")  \n",
    "    \n",
    "    return final_params, training_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee0affc",
   "metadata": {},
   "source": [
    "Digit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87085246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing neural net on digit data\n",
      "\n",
      "DIGITS: Training on 100 samples (10%)\n",
      "Epoch 0: Loss = 6.9313 | Train Acc = 0.1600 | Val Acc = 0.1540\n",
      "Epoch 100: Loss = 3.2331 | Train Acc = 0.1200 | Val Acc = 0.0740\n",
      "Epoch 200: Loss = 2.8850 | Train Acc = 0.3000 | Val Acc = 0.2340\n",
      "Epoch 300: Loss = 1.4134 | Train Acc = 0.8300 | Val Acc = 0.4960\n",
      "Epoch 400: Loss = 0.2462 | Train Acc = 1.0000 | Val Acc = 0.5900\n",
      "Epoch 500: Loss = 0.0454 | Train Acc = 1.0000 | Val Acc = 0.6080\n",
      "Epoch 600: Loss = 0.0207 | Train Acc = 1.0000 | Val Acc = 0.6120\n",
      "Epoch 700: Loss = 0.0125 | Train Acc = 1.0000 | Val Acc = 0.6120\n",
      "Epoch 800: Loss = 0.0087 | Train Acc = 1.0000 | Val Acc = 0.6120\n",
      "Epoch 900: Loss = 0.0066 | Train Acc = 1.0000 | Val Acc = 0.6100\n",
      "Epoch 999: Loss = 0.0052 | Train Acc = 1.0000 | Val Acc = 0.6100\n",
      "Final Test Accuracy: 0.6320\n",
      "Training Time: 9.54 seconds\n",
      "DIGITS Test Accuracy with 100 samples: 0.6320\n",
      "Training Time: 9.54 seconds\n",
      "\n",
      "Digit Classification Results:\n",
      "Model  Samples  Data %  Training Time  Test Accuracy  Validation Accuracy  Epoch\n",
      "Digit      100    10.0          9.539          0.632                0.612      1\n",
      "\n",
      "DIGITS: Training on 200 samples (20%)\n",
      "Epoch 0: Loss = 6.9313 | Train Acc = 0.0800 | Val Acc = 0.0820\n",
      "Epoch 100: Loss = 3.2589 | Train Acc = 0.1200 | Val Acc = 0.0800\n",
      "Epoch 200: Loss = 3.1981 | Train Acc = 0.2200 | Val Acc = 0.2060\n",
      "Epoch 300: Loss = 1.8049 | Train Acc = 0.6800 | Val Acc = 0.5040\n",
      "Epoch 400: Loss = 0.7303 | Train Acc = 0.9450 | Val Acc = 0.6580\n",
      "Epoch 500: Loss = 0.1575 | Train Acc = 1.0000 | Val Acc = 0.6940\n",
      "Epoch 600: Loss = 0.0522 | Train Acc = 1.0000 | Val Acc = 0.6860\n",
      "Epoch 700: Loss = 0.0267 | Train Acc = 1.0000 | Val Acc = 0.6880\n",
      "Epoch 800: Loss = 0.0169 | Train Acc = 1.0000 | Val Acc = 0.6920\n",
      "Epoch 900: Loss = 0.0120 | Train Acc = 1.0000 | Val Acc = 0.6920\n",
      "Epoch 999: Loss = 0.0091 | Train Acc = 1.0000 | Val Acc = 0.6920\n",
      "Final Test Accuracy: 0.6900\n",
      "Training Time: 7.28 seconds\n",
      "DIGITS Test Accuracy with 200 samples: 0.6900\n",
      "Training Time: 7.28 seconds\n",
      "\n",
      "Digit Classification Results:\n",
      "Model  Samples  Data %  Training Time  Test Accuracy  Validation Accuracy  Epoch\n",
      "Digit      100    10.0         9.5390          0.632                0.612      1\n",
      "Digit      200    20.0         7.2784          0.690                0.694      2\n",
      "\n",
      "DIGITS: Training on 300 samples (30%)\n",
      "Epoch 0: Loss = 6.9313 | Train Acc = 0.0900 | Val Acc = 0.0940\n",
      "Epoch 100: Loss = 3.2590 | Train Acc = 0.1200 | Val Acc = 0.1180\n",
      "Epoch 200: Loss = 3.2154 | Train Acc = 0.1200 | Val Acc = 0.1180\n",
      "Epoch 300: Loss = 2.0085 | Train Acc = 0.5867 | Val Acc = 0.5060\n",
      "Epoch 400: Loss = 1.0383 | Train Acc = 0.8533 | Val Acc = 0.6720\n",
      "Epoch 500: Loss = 0.4517 | Train Acc = 0.9633 | Val Acc = 0.7180\n",
      "Epoch 600: Loss = 0.1669 | Train Acc = 0.9967 | Val Acc = 0.7180\n",
      "Epoch 700: Loss = 0.0652 | Train Acc = 1.0000 | Val Acc = 0.7260\n",
      "Epoch 800: Loss = 0.0344 | Train Acc = 1.0000 | Val Acc = 0.7280\n",
      "Epoch 900: Loss = 0.0218 | Train Acc = 1.0000 | Val Acc = 0.7280\n",
      "Epoch 999: Loss = 0.0155 | Train Acc = 1.0000 | Val Acc = 0.7300\n",
      "Final Test Accuracy: 0.7200\n",
      "Training Time: 8.95 seconds\n",
      "DIGITS Test Accuracy with 300 samples: 0.7200\n",
      "Training Time: 8.95 seconds\n",
      "\n",
      "Digit Classification Results:\n",
      "Model  Samples  Data %  Training Time  Test Accuracy  Validation Accuracy  Epoch\n",
      "Digit      100    10.0         9.5390          0.632                0.612      1\n",
      "Digit      200    20.0         7.2784          0.690                0.694      2\n",
      "Digit      300    30.0         8.9538          0.720                0.730      3\n",
      "\n",
      "DIGITS: Training on 400 samples (40%)\n",
      "Epoch 0: Loss = 6.9313 | Train Acc = 0.0725 | Val Acc = 0.0240\n",
      "Epoch 100: Loss = 3.2599 | Train Acc = 0.1350 | Val Acc = 0.0900\n",
      "Epoch 200: Loss = 3.2259 | Train Acc = 0.1300 | Val Acc = 0.0860\n",
      "Epoch 300: Loss = 2.0894 | Train Acc = 0.5950 | Val Acc = 0.5120\n",
      "Epoch 400: Loss = 1.1459 | Train Acc = 0.8275 | Val Acc = 0.6820\n",
      "Epoch 500: Loss = 0.5504 | Train Acc = 0.9175 | Val Acc = 0.7380\n",
      "Epoch 600: Loss = 0.2486 | Train Acc = 0.9850 | Val Acc = 0.7420\n",
      "Epoch 700: Loss = 0.1032 | Train Acc = 1.0000 | Val Acc = 0.7480\n",
      "Epoch 800: Loss = 0.0513 | Train Acc = 1.0000 | Val Acc = 0.7520\n",
      "Epoch 900: Loss = 0.0311 | Train Acc = 1.0000 | Val Acc = 0.7580\n",
      "Epoch 999: Loss = 0.0214 | Train Acc = 1.0000 | Val Acc = 0.7560\n",
      "Final Test Accuracy: 0.7560\n",
      "Training Time: 12.73 seconds\n",
      "DIGITS Test Accuracy with 400 samples: 0.7560\n",
      "Training Time: 12.73 seconds\n",
      "\n",
      "Digit Classification Results:\n",
      "Model  Samples  Data %  Training Time  Test Accuracy  Validation Accuracy  Epoch\n",
      "Digit      100    10.0         9.5390          0.632                0.612      1\n",
      "Digit      200    20.0         7.2784          0.690                0.694      2\n",
      "Digit      300    30.0         8.9538          0.720                0.730      3\n",
      "Digit      400    40.0        12.7258          0.756                0.758      4\n",
      "\n",
      "DIGITS: Training on 500 samples (50%)\n",
      "Epoch 0: Loss = 6.9313 | Train Acc = 0.1220 | Val Acc = 0.1360\n",
      "Epoch 100: Loss = 3.2619 | Train Acc = 0.1260 | Val Acc = 0.1280\n",
      "Epoch 200: Loss = 3.2268 | Train Acc = 0.2240 | Val Acc = 0.2340\n",
      "Epoch 300: Loss = 2.1962 | Train Acc = 0.5880 | Val Acc = 0.5140\n",
      "Epoch 400: Loss = 1.2700 | Train Acc = 0.7960 | Val Acc = 0.6780\n",
      "Epoch 500: Loss = 0.6614 | Train Acc = 0.8980 | Val Acc = 0.7260\n",
      "Epoch 600: Loss = 0.3267 | Train Acc = 0.9840 | Val Acc = 0.7580\n",
      "Epoch 700: Loss = 0.1413 | Train Acc = 0.9980 | Val Acc = 0.7720\n",
      "Epoch 800: Loss = 0.0696 | Train Acc = 1.0000 | Val Acc = 0.7700\n",
      "Epoch 900: Loss = 0.0408 | Train Acc = 1.0000 | Val Acc = 0.7620\n",
      "Epoch 999: Loss = 0.0273 | Train Acc = 1.0000 | Val Acc = 0.7640\n",
      "Final Test Accuracy: 0.7480\n",
      "Training Time: 14.04 seconds\n",
      "DIGITS Test Accuracy with 500 samples: 0.7480\n",
      "Training Time: 14.04 seconds\n",
      "\n",
      "Digit Classification Results:\n",
      "Model  Samples  Data %  Training Time  Test Accuracy  Validation Accuracy  Epoch\n",
      "Digit      100    10.0         9.5390          0.632                0.612      1\n",
      "Digit      200    20.0         7.2784          0.690                0.694      2\n",
      "Digit      300    30.0         8.9538          0.720                0.730      3\n",
      "Digit      400    40.0        12.7258          0.756                0.758      4\n",
      "Digit      500    50.0        14.0393          0.748                0.772      5\n",
      "\n",
      "DIGITS: Training on 600 samples (60%)\n",
      "Epoch 0: Loss = 6.9313 | Train Acc = 0.1200 | Val Acc = 0.1360\n",
      "Epoch 100: Loss = 3.2667 | Train Acc = 0.1300 | Val Acc = 0.1400\n",
      "Epoch 200: Loss = 3.2361 | Train Acc = 0.1933 | Val Acc = 0.2040\n",
      "Epoch 300: Loss = 2.2518 | Train Acc = 0.5833 | Val Acc = 0.5400\n",
      "Epoch 400: Loss = 1.3031 | Train Acc = 0.7950 | Val Acc = 0.6960\n",
      "Epoch 500: Loss = 0.7062 | Train Acc = 0.9033 | Val Acc = 0.7520\n",
      "Epoch 600: Loss = 0.3754 | Train Acc = 0.9683 | Val Acc = 0.7700\n",
      "Epoch 700: Loss = 0.1729 | Train Acc = 0.9933 | Val Acc = 0.7740\n",
      "Epoch 800: Loss = 0.0862 | Train Acc = 1.0000 | Val Acc = 0.7860\n",
      "Epoch 900: Loss = 0.0497 | Train Acc = 1.0000 | Val Acc = 0.7900\n",
      "Epoch 999: Loss = 0.0328 | Train Acc = 1.0000 | Val Acc = 0.7880\n",
      "Final Test Accuracy: 0.7580\n",
      "Training Time: 22.72 seconds\n",
      "DIGITS Test Accuracy with 600 samples: 0.7580\n",
      "Training Time: 22.72 seconds\n",
      "\n",
      "Digit Classification Results:\n",
      "Model  Samples  Data %  Training Time  Test Accuracy  Validation Accuracy  Epoch\n",
      "Digit      100    10.0         9.5390          0.632                0.612      1\n",
      "Digit      200    20.0         7.2784          0.690                0.694      2\n",
      "Digit      300    30.0         8.9538          0.720                0.730      3\n",
      "Digit      400    40.0        12.7258          0.756                0.758      4\n",
      "Digit      500    50.0        14.0393          0.748                0.772      5\n",
      "Digit      600    60.0        22.7225          0.758                0.790      6\n",
      "\n",
      "DIGITS: Training on 700 samples (70%)\n",
      "Epoch 0: Loss = 6.9313 | Train Acc = 0.1200 | Val Acc = 0.1360\n",
      "Epoch 100: Loss = 3.2667 | Train Acc = 0.1171 | Val Acc = 0.1080\n",
      "Epoch 200: Loss = 3.2372 | Train Acc = 0.1771 | Val Acc = 0.1860\n",
      "Epoch 300: Loss = 2.3847 | Train Acc = 0.5914 | Val Acc = 0.5620\n",
      "Epoch 400: Loss = 1.3534 | Train Acc = 0.7800 | Val Acc = 0.7080\n",
      "Epoch 500: Loss = 0.7850 | Train Acc = 0.8814 | Val Acc = 0.7680\n",
      "Epoch 600: Loss = 0.5105 | Train Acc = 0.9400 | Val Acc = 0.7480\n",
      "Epoch 700: Loss = 0.2263 | Train Acc = 0.9900 | Val Acc = 0.7840\n",
      "Epoch 800: Loss = 0.1166 | Train Acc = 0.9986 | Val Acc = 0.7860\n",
      "Epoch 900: Loss = 0.0663 | Train Acc = 1.0000 | Val Acc = 0.7840\n",
      "Epoch 999: Loss = 0.0426 | Train Acc = 1.0000 | Val Acc = 0.7880\n",
      "Final Test Accuracy: 0.7540\n",
      "Training Time: 18.27 seconds\n",
      "DIGITS Test Accuracy with 700 samples: 0.7540\n",
      "Training Time: 18.27 seconds\n",
      "\n",
      "Digit Classification Results:\n",
      "Model  Samples  Data %  Training Time  Test Accuracy  Validation Accuracy  Epoch\n",
      "Digit      100    10.0         9.5390          0.632                0.612      1\n",
      "Digit      200    20.0         7.2784          0.690                0.694      2\n",
      "Digit      300    30.0         8.9538          0.720                0.730      3\n",
      "Digit      400    40.0        12.7258          0.756                0.758      4\n",
      "Digit      500    50.0        14.0393          0.748                0.772      5\n",
      "Digit      600    60.0        22.7225          0.758                0.790      6\n",
      "Digit      700    70.0        18.2720          0.754                0.788      7\n",
      "\n",
      "DIGITS: Training on 800 samples (80%)\n",
      "Epoch 0: Loss = 6.9313 | Train Acc = 0.1212 | Val Acc = 0.1360\n",
      "Epoch 100: Loss = 3.2677 | Train Acc = 0.1425 | Val Acc = 0.1560\n",
      "Epoch 200: Loss = 3.2365 | Train Acc = 0.1950 | Val Acc = 0.2120\n",
      "Epoch 300: Loss = 2.3355 | Train Acc = 0.5875 | Val Acc = 0.5620\n",
      "Epoch 400: Loss = 1.3650 | Train Acc = 0.7712 | Val Acc = 0.7040\n",
      "Epoch 500: Loss = 0.8453 | Train Acc = 0.8650 | Val Acc = 0.7600\n",
      "Epoch 600: Loss = 0.4876 | Train Acc = 0.9437 | Val Acc = 0.7760\n",
      "Epoch 700: Loss = 0.2526 | Train Acc = 0.9838 | Val Acc = 0.7860\n",
      "Epoch 800: Loss = 0.1362 | Train Acc = 0.9962 | Val Acc = 0.7980\n",
      "Epoch 900: Loss = 0.0795 | Train Acc = 0.9988 | Val Acc = 0.8020\n",
      "Epoch 999: Loss = 0.0510 | Train Acc = 1.0000 | Val Acc = 0.7980\n",
      "Final Test Accuracy: 0.7820\n",
      "Training Time: 19.41 seconds\n",
      "DIGITS Test Accuracy with 800 samples: 0.7820\n",
      "Training Time: 19.41 seconds\n",
      "\n",
      "Digit Classification Results:\n",
      "Model  Samples  Data %  Training Time  Test Accuracy  Validation Accuracy  Epoch\n",
      "Digit      100    10.0         9.5390          0.632                0.612      1\n",
      "Digit      200    20.0         7.2784          0.690                0.694      2\n",
      "Digit      300    30.0         8.9538          0.720                0.730      3\n",
      "Digit      400    40.0        12.7258          0.756                0.758      4\n",
      "Digit      500    50.0        14.0393          0.748                0.772      5\n",
      "Digit      600    60.0        22.7225          0.758                0.790      6\n",
      "Digit      700    70.0        18.2720          0.754                0.788      7\n",
      "Digit      800    80.0        19.4093          0.782                0.802      8\n",
      "\n",
      "DIGITS: Training on 900 samples (90%)\n",
      "Epoch 0: Loss = 6.9313 | Train Acc = 0.1189 | Val Acc = 0.1360\n",
      "Epoch 100: Loss = 3.2662 | Train Acc = 0.1189 | Val Acc = 0.1120\n",
      "Epoch 200: Loss = 3.2380 | Train Acc = 0.1844 | Val Acc = 0.1900\n",
      "Epoch 300: Loss = 2.3012 | Train Acc = 0.5878 | Val Acc = 0.5460\n",
      "Epoch 400: Loss = 1.3838 | Train Acc = 0.7689 | Val Acc = 0.6980\n",
      "Epoch 500: Loss = 0.8559 | Train Acc = 0.8722 | Val Acc = 0.7320\n",
      "Epoch 600: Loss = 0.5450 | Train Acc = 0.9367 | Val Acc = 0.7520\n",
      "Epoch 700: Loss = 0.3206 | Train Acc = 0.9700 | Val Acc = 0.7740\n",
      "Epoch 800: Loss = 0.1712 | Train Acc = 0.9956 | Val Acc = 0.7820\n",
      "Epoch 900: Loss = 0.1011 | Train Acc = 0.9978 | Val Acc = 0.7800\n",
      "Epoch 999: Loss = 0.0638 | Train Acc = 1.0000 | Val Acc = 0.7840\n",
      "Final Test Accuracy: 0.8080\n",
      "Training Time: 21.43 seconds\n",
      "DIGITS Test Accuracy with 900 samples: 0.8080\n",
      "Training Time: 21.43 seconds\n",
      "\n",
      "Digit Classification Results:\n",
      "Model  Samples  Data %  Training Time  Test Accuracy  Validation Accuracy  Epoch\n",
      "Digit      100    10.0         9.5390          0.632                0.612      1\n",
      "Digit      200    20.0         7.2784          0.690                0.694      2\n",
      "Digit      300    30.0         8.9538          0.720                0.730      3\n",
      "Digit      400    40.0        12.7258          0.756                0.758      4\n",
      "Digit      500    50.0        14.0393          0.748                0.772      5\n",
      "Digit      600    60.0        22.7225          0.758                0.790      6\n",
      "Digit      700    70.0        18.2720          0.754                0.788      7\n",
      "Digit      800    80.0        19.4093          0.782                0.802      8\n",
      "Digit      900    90.0        21.4259          0.808                0.784      9\n",
      "\n",
      "DIGITS: Training on 1000 samples (100%)\n",
      "Epoch 0: Loss = 6.9313 | Train Acc = 0.1500 | Val Acc = 0.1580\n",
      "Epoch 100: Loss = 3.2688 | Train Acc = 0.1530 | Val Acc = 0.1300\n",
      "Epoch 200: Loss = 3.2416 | Train Acc = 0.2500 | Val Acc = 0.2520\n",
      "Epoch 300: Loss = 2.3491 | Train Acc = 0.5770 | Val Acc = 0.5560\n",
      "Epoch 400: Loss = 1.3924 | Train Acc = 0.7580 | Val Acc = 0.6980\n",
      "Epoch 500: Loss = 0.8714 | Train Acc = 0.8750 | Val Acc = 0.7540\n",
      "Epoch 600: Loss = 0.5754 | Train Acc = 0.9340 | Val Acc = 0.7800\n",
      "Epoch 700: Loss = 0.3404 | Train Acc = 0.9660 | Val Acc = 0.7960\n",
      "Epoch 800: Loss = 0.1981 | Train Acc = 0.9870 | Val Acc = 0.7900\n",
      "Epoch 900: Loss = 0.1199 | Train Acc = 0.9970 | Val Acc = 0.7920\n",
      "Epoch 999: Loss = 0.0756 | Train Acc = 1.0000 | Val Acc = 0.7920\n",
      "Final Test Accuracy: 0.7920\n",
      "Training Time: 24.45 seconds\n",
      "DIGITS Test Accuracy with 1000 samples: 0.7920\n",
      "Training Time: 24.45 seconds\n",
      "\n",
      "Digit Classification Results:\n",
      "Model  Samples  Data %  Training Time  Test Accuracy  Validation Accuracy  Epoch\n",
      "Digit      100    10.0         9.5390          0.632                0.612      1\n",
      "Digit      200    20.0         7.2784          0.690                0.694      2\n",
      "Digit      300    30.0         8.9538          0.720                0.730      3\n",
      "Digit      400    40.0        12.7258          0.756                0.758      4\n",
      "Digit      500    50.0        14.0393          0.748                0.772      5\n",
      "Digit      600    60.0        22.7225          0.758                0.790      6\n",
      "Digit      700    70.0        18.2720          0.754                0.788      7\n",
      "Digit      800    80.0        19.4093          0.782                0.802      8\n",
      "Digit      900    90.0        21.4259          0.808                0.784      9\n",
      "Digit     1000   100.0        24.4544          0.792                0.796     10\n"
     ]
    }
   ],
   "source": [
    "# Initialize results storage\n",
    "training_data = []\n",
    "\n",
    "print(\"Testing neural net on digit data\")\n",
    "\n",
    "# Load and preprocess data\n",
    "X_train_raw, y_train_raw = load_dataset(train_data_file, train_label_file, size=NUM_TRAINING)\n",
    "X_val_raw, y_val_raw = load_dataset(val_data_file, val_label_file, size=NUM_VALIDATION)\n",
    "X_test_raw, y_test_raw = load_dataset(test_data_file, test_label_file, size=NUM_TESTING)\n",
    "\n",
    "X_train = np.array(X_train_raw).T\n",
    "X_val = np.array(X_val_raw).T\n",
    "X_test = np.array(X_test_raw).T\n",
    "\n",
    "y_train = one_hot_encode(y_train_raw)\n",
    "y_val = one_hot_encode(y_val_raw)\n",
    "y_test = one_hot_encode(y_test_raw)\n",
    "\n",
    "# Train on increasing percentages of DIGIT data \n",
    "percentages = [0.1 * i for i in range(1, 11)]  # 10% to 100%\n",
    "total_digit_samples = X_train.shape[1]\n",
    "\n",
    "# Training loop\n",
    "for pct in percentages:\n",
    "    n = int(pct * total_digit_samples)    \n",
    "    X_subset = X_train[:, :n]\n",
    "    y_subset = y_train[:, :n]\n",
    "\n",
    "    print(f\"\\nDIGITS: Training on {n} samples ({int(pct * 100)}%)\")\n",
    "    \n",
    "    trained_params, train_time = train_neural_net(\n",
    "        X_subset, y_subset,\n",
    "        X_test, y_test,\n",
    "        input_size=784, h1=128, h2=64, output_size=10,\n",
    "        epochs=1000, lr=0.1,\n",
    "        X_val=X_val, y_val=y_val,\n",
    "        early_stopping=True, patience=10\n",
    "    )\n",
    "\n",
    "    # Get predictions and accuracies\n",
    "    test_preds = predict_nn(X_test, trained_params)\n",
    "    test_acc = evaluate(test_preds, np.argmax(y_test, axis=0))\n",
    "    \n",
    "    # Get validation accuracy\n",
    "    val_preds = predict_nn(X_val, trained_params)\n",
    "    val_acc = evaluate(val_preds, np.argmax(y_val, axis=0))\n",
    "    \n",
    "    # Store results in dictionary\n",
    "    batch_results = {\n",
    "        'Model': 'Digit',\n",
    "        'Samples': n,\n",
    "        'Data %': pct * 100,\n",
    "        'Training Time': train_time,\n",
    "        'Test Accuracy': test_acc,\n",
    "        'Validation Accuracy': val_acc,\n",
    "        'Epoch': len(training_data) + 1  # Add epoch number for tracking\n",
    "    }\n",
    "    \n",
    "    # Append to training data list\n",
    "    training_data.append(batch_results)\n",
    "    \n",
    "    # Print current results\n",
    "    print(f\"DIGITS Test Accuracy with {n} samples: {test_acc:.4f}\")\n",
    "    print(f\"Training Time: {train_time:.2f} seconds\")\n",
    "\n",
    "    # Create DataFrame from all collected results\n",
    "    digit_df = pd.DataFrame(training_data)\n",
    "    \n",
    "    # Display summary of all results so far\n",
    "    print(\"\\nDigit Classification Results:\")\n",
    "    print(digit_df.round(4).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef98d09",
   "metadata": {},
   "source": [
    "Face data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c5dfbae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing neural net on face data\n",
      "\n",
      " FACES: Training on 45 samples (10%)\n",
      "Epoch 0: Loss = 0.7683 | Train Acc = 0.5333 | Val Acc = 0.5183\n",
      "Epoch 100: Loss = 0.7654 | Train Acc = 0.5333 | Val Acc = 0.5183\n",
      "Epoch 200: Loss = 0.3004 | Train Acc = 1.0000 | Val Acc = 0.7276\n",
      "Epoch 300: Loss = 0.1464 | Train Acc = 1.0000 | Val Acc = 0.7475\n",
      "Epoch 400: Loss = 0.1341 | Train Acc = 1.0000 | Val Acc = 0.7409\n",
      "Epoch 500: Loss = 0.1384 | Train Acc = 1.0000 | Val Acc = 0.7409\n",
      "Epoch 600: Loss = 0.1309 | Train Acc = 1.0000 | Val Acc = 0.7309\n",
      "Epoch 700: Loss = 0.1332 | Train Acc = 1.0000 | Val Acc = 0.7375\n",
      "Epoch 800: Loss = 0.1355 | Train Acc = 1.0000 | Val Acc = 0.7575\n",
      "Epoch 900: Loss = 0.1356 | Train Acc = 1.0000 | Val Acc = 0.7243\n",
      "Epoch 999: Loss = 0.1518 | Train Acc = 1.0000 | Val Acc = 0.7276\n",
      "Final Test Accuracy: 0.7867\n",
      "Training Time: 4.53 seconds\n",
      "FACES Test Accuracy with 45 samples: 0.7867\n",
      "Training Time: 4.53 seconds\n",
      "\n",
      "Complete Classification Results:\n",
      "Model  Samples  Data %  Training Time  Test Accuracy  Validation Accuracy  Epoch\n",
      "Digit      100    10.0         9.5390         0.6320               0.6120      1\n",
      "Digit      200    20.0         7.2784         0.6900               0.6940      2\n",
      "Digit      300    30.0         8.9538         0.7200               0.7300      3\n",
      "Digit      400    40.0        12.7258         0.7560               0.7580      4\n",
      "Digit      500    50.0        14.0393         0.7480               0.7720      5\n",
      "Digit      600    60.0        22.7225         0.7580               0.7900      6\n",
      "Digit      700    70.0        18.2720         0.7540               0.7880      7\n",
      "Digit      800    80.0        19.4093         0.7820               0.8020      8\n",
      "Digit      900    90.0        21.4259         0.8080               0.7840      9\n",
      "Digit     1000   100.0        24.4544         0.7920               0.7960     10\n",
      " Face       45    10.0         4.5335         0.7867               0.7575     11\n",
      "\n",
      " FACES: Training on 90 samples (20%)\n",
      "Epoch 0: Loss = 0.7307 | Train Acc = 0.5111 | Val Acc = 0.5183\n",
      "Epoch 100: Loss = 0.7303 | Train Acc = 0.5111 | Val Acc = 0.5183\n",
      "Epoch 200: Loss = 0.7280 | Train Acc = 0.5111 | Val Acc = 0.5183\n",
      "Epoch 300: Loss = 0.1415 | Train Acc = 1.0000 | Val Acc = 0.8272\n",
      "Epoch 400: Loss = 0.0798 | Train Acc = 1.0000 | Val Acc = 0.8439\n",
      "Epoch 500: Loss = 0.1073 | Train Acc = 1.0000 | Val Acc = 0.8173\n",
      "Epoch 600: Loss = 0.0948 | Train Acc = 1.0000 | Val Acc = 0.8439\n",
      "Epoch 700: Loss = 0.0751 | Train Acc = 1.0000 | Val Acc = 0.8306\n",
      "Epoch 800: Loss = 0.0951 | Train Acc = 1.0000 | Val Acc = 0.8306\n",
      "Epoch 900: Loss = 0.0745 | Train Acc = 1.0000 | Val Acc = 0.8306\n",
      "Epoch 999: Loss = 0.0774 | Train Acc = 1.0000 | Val Acc = 0.7841\n",
      "Final Test Accuracy: 0.8400\n",
      "Training Time: 10.54 seconds\n",
      "FACES Test Accuracy with 90 samples: 0.8400\n",
      "Training Time: 10.54 seconds\n",
      "\n",
      "Complete Classification Results:\n",
      "Model  Samples  Data %  Training Time  Test Accuracy  Validation Accuracy  Epoch\n",
      "Digit      100    10.0         9.5390         0.6320               0.6120      1\n",
      "Digit      200    20.0         7.2784         0.6900               0.6940      2\n",
      "Digit      300    30.0         8.9538         0.7200               0.7300      3\n",
      "Digit      400    40.0        12.7258         0.7560               0.7580      4\n",
      "Digit      500    50.0        14.0393         0.7480               0.7720      5\n",
      "Digit      600    60.0        22.7225         0.7580               0.7900      6\n",
      "Digit      700    70.0        18.2720         0.7540               0.7880      7\n",
      "Digit      800    80.0        19.4093         0.7820               0.8020      8\n",
      "Digit      900    90.0        21.4259         0.8080               0.7840      9\n",
      "Digit     1000   100.0        24.4544         0.7920               0.7960     10\n",
      " Face       45    10.0         4.5335         0.7867               0.7575     11\n",
      " Face       90    20.0        10.5350         0.8400               0.8439     12\n",
      "\n",
      " FACES: Training on 135 samples (30%)\n",
      "Epoch 0: Loss = 0.7182 | Train Acc = 0.5259 | Val Acc = 0.5183\n",
      "Epoch 100: Loss = 0.7167 | Train Acc = 0.5259 | Val Acc = 0.5183\n",
      "Epoch 200: Loss = 0.7163 | Train Acc = 0.5259 | Val Acc = 0.5183\n",
      "Epoch 300: Loss = 0.6086 | Train Acc = 0.9556 | Val Acc = 0.5781\n",
      "Epoch 400: Loss = 0.1123 | Train Acc = 1.0000 | Val Acc = 0.8306\n",
      "Epoch 500: Loss = 0.0760 | Train Acc = 1.0000 | Val Acc = 0.8173\n",
      "Epoch 600: Loss = 0.0513 | Train Acc = 1.0000 | Val Acc = 0.8272\n",
      "Epoch 700: Loss = 0.0639 | Train Acc = 1.0000 | Val Acc = 0.8007\n",
      "Epoch 800: Loss = 0.0609 | Train Acc = 1.0000 | Val Acc = 0.8073\n",
      "Epoch 900: Loss = 0.0653 | Train Acc = 1.0000 | Val Acc = 0.8140\n",
      "Epoch 999: Loss = 0.0538 | Train Acc = 1.0000 | Val Acc = 0.8073\n",
      "Final Test Accuracy: 0.8133\n",
      "Training Time: 10.94 seconds\n",
      "FACES Test Accuracy with 135 samples: 0.8133\n",
      "Training Time: 10.94 seconds\n",
      "\n",
      "Complete Classification Results:\n",
      "Model  Samples  Data %  Training Time  Test Accuracy  Validation Accuracy  Epoch\n",
      "Digit      100    10.0         9.5390         0.6320               0.6120      1\n",
      "Digit      200    20.0         7.2784         0.6900               0.6940      2\n",
      "Digit      300    30.0         8.9538         0.7200               0.7300      3\n",
      "Digit      400    40.0        12.7258         0.7560               0.7580      4\n",
      "Digit      500    50.0        14.0393         0.7480               0.7720      5\n",
      "Digit      600    60.0        22.7225         0.7580               0.7900      6\n",
      "Digit      700    70.0        18.2720         0.7540               0.7880      7\n",
      "Digit      800    80.0        19.4093         0.7820               0.8020      8\n",
      "Digit      900    90.0        21.4259         0.8080               0.7840      9\n",
      "Digit     1000   100.0        24.4544         0.7920               0.7960     10\n",
      " Face       45    10.0         4.5335         0.7867               0.7575     11\n",
      " Face       90    20.0        10.5350         0.8400               0.8439     12\n",
      " Face      135    30.0        10.9448         0.8133               0.8306     13\n",
      "\n",
      " FACES: Training on 180 samples (40%)\n",
      "Epoch 0: Loss = 0.7119 | Train Acc = 0.5278 | Val Acc = 0.5183\n",
      "Epoch 100: Loss = 0.7103 | Train Acc = 0.5278 | Val Acc = 0.5183\n",
      "Epoch 200: Loss = 0.7100 | Train Acc = 0.5278 | Val Acc = 0.5183\n",
      "Epoch 300: Loss = 0.6134 | Train Acc = 0.6222 | Val Acc = 0.5183\n",
      "Epoch 400: Loss = 0.0827 | Train Acc = 1.0000 | Val Acc = 0.7409\n",
      "Epoch 500: Loss = 0.0645 | Train Acc = 1.0000 | Val Acc = 0.7542\n",
      "Epoch 600: Loss = 0.0569 | Train Acc = 1.0000 | Val Acc = 0.7442\n",
      "Epoch 700: Loss = 0.0494 | Train Acc = 1.0000 | Val Acc = 0.7442\n",
      "Epoch 800: Loss = 0.0418 | Train Acc = 1.0000 | Val Acc = 0.7508\n",
      "Epoch 900: Loss = 0.0463 | Train Acc = 1.0000 | Val Acc = 0.7342\n",
      "Epoch 999: Loss = 0.0447 | Train Acc = 1.0000 | Val Acc = 0.7375\n",
      "Final Test Accuracy: 0.7333\n",
      "Training Time: 10.66 seconds\n",
      "FACES Test Accuracy with 180 samples: 0.7333\n",
      "Training Time: 10.66 seconds\n",
      "\n",
      "Complete Classification Results:\n",
      "Model  Samples  Data %  Training Time  Test Accuracy  Validation Accuracy  Epoch\n",
      "Digit      100    10.0         9.5390         0.6320               0.6120      1\n",
      "Digit      200    20.0         7.2784         0.6900               0.6940      2\n",
      "Digit      300    30.0         8.9538         0.7200               0.7300      3\n",
      "Digit      400    40.0        12.7258         0.7560               0.7580      4\n",
      "Digit      500    50.0        14.0393         0.7480               0.7720      5\n",
      "Digit      600    60.0        22.7225         0.7580               0.7900      6\n",
      "Digit      700    70.0        18.2720         0.7540               0.7880      7\n",
      "Digit      800    80.0        19.4093         0.7820               0.8020      8\n",
      "Digit      900    90.0        21.4259         0.8080               0.7840      9\n",
      "Digit     1000   100.0        24.4544         0.7920               0.7960     10\n",
      " Face       45    10.0         4.5335         0.7867               0.7575     11\n",
      " Face       90    20.0        10.5350         0.8400               0.8439     12\n",
      " Face      135    30.0        10.9448         0.8133               0.8306     13\n",
      " Face      180    40.0        10.6640         0.7333               0.7542     14\n",
      "\n",
      " FACES: Training on 225 samples (50%)\n",
      "Epoch 0: Loss = 0.7082 | Train Acc = 0.4933 | Val Acc = 0.4817\n",
      "Epoch 100: Loss = 0.7080 | Train Acc = 0.5022 | Val Acc = 0.4817\n",
      "Epoch 200: Loss = 0.7079 | Train Acc = 0.5022 | Val Acc = 0.4817\n",
      "Epoch 300: Loss = 0.7010 | Train Acc = 0.9111 | Val Acc = 0.6678\n",
      "Epoch 400: Loss = 0.1527 | Train Acc = 1.0000 | Val Acc = 0.7841\n",
      "Epoch 500: Loss = 0.0818 | Train Acc = 1.0000 | Val Acc = 0.7841\n",
      "Epoch 600: Loss = 0.0579 | Train Acc = 1.0000 | Val Acc = 0.7940\n",
      "Epoch 700: Loss = 0.0467 | Train Acc = 1.0000 | Val Acc = 0.7774\n",
      "Epoch 800: Loss = 0.0503 | Train Acc = 1.0000 | Val Acc = 0.7741\n",
      "Epoch 900: Loss = 0.0496 | Train Acc = 1.0000 | Val Acc = 0.7874\n",
      "Epoch 999: Loss = 0.0477 | Train Acc = 1.0000 | Val Acc = 0.7807\n",
      "Final Test Accuracy: 0.8067\n",
      "Training Time: 11.76 seconds\n",
      "FACES Test Accuracy with 225 samples: 0.8067\n",
      "Training Time: 11.76 seconds\n",
      "\n",
      "Complete Classification Results:\n",
      "Model  Samples  Data %  Training Time  Test Accuracy  Validation Accuracy  Epoch\n",
      "Digit      100    10.0         9.5390         0.6320               0.6120      1\n",
      "Digit      200    20.0         7.2784         0.6900               0.6940      2\n",
      "Digit      300    30.0         8.9538         0.7200               0.7300      3\n",
      "Digit      400    40.0        12.7258         0.7560               0.7580      4\n",
      "Digit      500    50.0        14.0393         0.7480               0.7720      5\n",
      "Digit      600    60.0        22.7225         0.7580               0.7900      6\n",
      "Digit      700    70.0        18.2720         0.7540               0.7880      7\n",
      "Digit      800    80.0        19.4093         0.7820               0.8020      8\n",
      "Digit      900    90.0        21.4259         0.8080               0.7840      9\n",
      "Digit     1000   100.0        24.4544         0.7920               0.7960     10\n",
      " Face       45    10.0         4.5335         0.7867               0.7575     11\n",
      " Face       90    20.0        10.5350         0.8400               0.8439     12\n",
      " Face      135    30.0        10.9448         0.8133               0.8306     13\n",
      " Face      180    40.0        10.6640         0.7333               0.7542     14\n",
      " Face      225    50.0        11.7580         0.8067               0.7940     15\n",
      "\n",
      " FACES: Training on 270 samples (60%)\n",
      "Epoch 0: Loss = 0.7057 | Train Acc = 0.5148 | Val Acc = 0.5183\n",
      "Epoch 100: Loss = 0.7052 | Train Acc = 0.5148 | Val Acc = 0.5183\n",
      "Epoch 200: Loss = 0.7049 | Train Acc = 0.5148 | Val Acc = 0.5183\n",
      "Epoch 300: Loss = 0.7030 | Train Acc = 0.5148 | Val Acc = 0.5183\n",
      "Epoch 400: Loss = 0.3465 | Train Acc = 1.0000 | Val Acc = 0.8073\n",
      "Epoch 500: Loss = 0.0789 | Train Acc = 1.0000 | Val Acc = 0.8239\n",
      "Epoch 600: Loss = 0.0457 | Train Acc = 1.0000 | Val Acc = 0.8239\n",
      "Epoch 700: Loss = 0.0443 | Train Acc = 1.0000 | Val Acc = 0.8206\n",
      "Epoch 800: Loss = 0.0393 | Train Acc = 1.0000 | Val Acc = 0.8173\n",
      "Epoch 900: Loss = 0.0415 | Train Acc = 1.0000 | Val Acc = 0.8173\n",
      "Epoch 999: Loss = 0.0377 | Train Acc = 1.0000 | Val Acc = 0.8140\n",
      "Final Test Accuracy: 0.8133\n",
      "Training Time: 13.46 seconds\n",
      "FACES Test Accuracy with 270 samples: 0.8133\n",
      "Training Time: 13.46 seconds\n",
      "\n",
      "Complete Classification Results:\n",
      "Model  Samples  Data %  Training Time  Test Accuracy  Validation Accuracy  Epoch\n",
      "Digit      100    10.0         9.5390         0.6320               0.6120      1\n",
      "Digit      200    20.0         7.2784         0.6900               0.6940      2\n",
      "Digit      300    30.0         8.9538         0.7200               0.7300      3\n",
      "Digit      400    40.0        12.7258         0.7560               0.7580      4\n",
      "Digit      500    50.0        14.0393         0.7480               0.7720      5\n",
      "Digit      600    60.0        22.7225         0.7580               0.7900      6\n",
      "Digit      700    70.0        18.2720         0.7540               0.7880      7\n",
      "Digit      800    80.0        19.4093         0.7820               0.8020      8\n",
      "Digit      900    90.0        21.4259         0.8080               0.7840      9\n",
      "Digit     1000   100.0        24.4544         0.7920               0.7960     10\n",
      " Face       45    10.0         4.5335         0.7867               0.7575     11\n",
      " Face       90    20.0        10.5350         0.8400               0.8439     12\n",
      " Face      135    30.0        10.9448         0.8133               0.8306     13\n",
      " Face      180    40.0        10.6640         0.7333               0.7542     14\n",
      " Face      225    50.0        11.7580         0.8067               0.7940     15\n",
      " Face      270    60.0        13.4606         0.8133               0.8239     16\n",
      "\n",
      " FACES: Training on 315 samples (70%)\n",
      "Epoch 0: Loss = 0.7039 | Train Acc = 0.5111 | Val Acc = 0.5183\n",
      "Epoch 100: Loss = 0.7036 | Train Acc = 0.5111 | Val Acc = 0.5183\n",
      "Epoch 200: Loss = 0.7035 | Train Acc = 0.5111 | Val Acc = 0.5183\n",
      "Epoch 300: Loss = 0.7028 | Train Acc = 0.5111 | Val Acc = 0.5183\n",
      "Epoch 400: Loss = 0.6010 | Train Acc = 0.9587 | Val Acc = 0.7708\n",
      "Epoch 500: Loss = 0.1078 | Train Acc = 1.0000 | Val Acc = 0.8605\n",
      "Epoch 600: Loss = 0.0661 | Train Acc = 1.0000 | Val Acc = 0.8505\n",
      "Epoch 700: Loss = 0.0398 | Train Acc = 1.0000 | Val Acc = 0.8538\n",
      "Epoch 800: Loss = 0.0376 | Train Acc = 1.0000 | Val Acc = 0.8605\n",
      "Epoch 900: Loss = 0.0408 | Train Acc = 1.0000 | Val Acc = 0.8605\n",
      "Epoch 999: Loss = 0.0375 | Train Acc = 1.0000 | Val Acc = 0.8538\n",
      "Final Test Accuracy: 0.8533\n",
      "Training Time: 14.64 seconds\n",
      "FACES Test Accuracy with 315 samples: 0.8533\n",
      "Training Time: 14.64 seconds\n",
      "\n",
      "Complete Classification Results:\n",
      "Model  Samples  Data %  Training Time  Test Accuracy  Validation Accuracy  Epoch\n",
      "Digit      100    10.0         9.5390         0.6320               0.6120      1\n",
      "Digit      200    20.0         7.2784         0.6900               0.6940      2\n",
      "Digit      300    30.0         8.9538         0.7200               0.7300      3\n",
      "Digit      400    40.0        12.7258         0.7560               0.7580      4\n",
      "Digit      500    50.0        14.0393         0.7480               0.7720      5\n",
      "Digit      600    60.0        22.7225         0.7580               0.7900      6\n",
      "Digit      700    70.0        18.2720         0.7540               0.7880      7\n",
      "Digit      800    80.0        19.4093         0.7820               0.8020      8\n",
      "Digit      900    90.0        21.4259         0.8080               0.7840      9\n",
      "Digit     1000   100.0        24.4544         0.7920               0.7960     10\n",
      " Face       45    10.0         4.5335         0.7867               0.7575     11\n",
      " Face       90    20.0        10.5350         0.8400               0.8439     12\n",
      " Face      135    30.0        10.9448         0.8133               0.8306     13\n",
      " Face      180    40.0        10.6640         0.7333               0.7542     14\n",
      " Face      225    50.0        11.7580         0.8067               0.7940     15\n",
      " Face      270    60.0        13.4606         0.8133               0.8239     16\n",
      " Face      315    70.0        14.6420         0.8533               0.8605     17\n",
      "\n",
      " FACES: Training on 360 samples (80%)\n",
      "Epoch 0: Loss = 0.7026 | Train Acc = 0.5111 | Val Acc = 0.5183\n",
      "Epoch 100: Loss = 0.7022 | Train Acc = 0.5111 | Val Acc = 0.5183\n",
      "Epoch 200: Loss = 0.7022 | Train Acc = 0.5111 | Val Acc = 0.5183\n",
      "Epoch 300: Loss = 0.7011 | Train Acc = 0.5111 | Val Acc = 0.5183\n",
      "Epoch 400: Loss = 0.5838 | Train Acc = 0.9750 | Val Acc = 0.8007\n",
      "Epoch 500: Loss = 0.1131 | Train Acc = 1.0000 | Val Acc = 0.8605\n",
      "Epoch 600: Loss = 0.0534 | Train Acc = 1.0000 | Val Acc = 0.8571\n",
      "Epoch 700: Loss = 0.0414 | Train Acc = 1.0000 | Val Acc = 0.8538\n",
      "Epoch 800: Loss = 0.0508 | Train Acc = 1.0000 | Val Acc = 0.8472\n",
      "Epoch 900: Loss = 0.0441 | Train Acc = 1.0000 | Val Acc = 0.8538\n",
      "Epoch 999: Loss = 0.0310 | Train Acc = 1.0000 | Val Acc = 0.8339\n",
      "Final Test Accuracy: 0.8533\n",
      "Training Time: 16.45 seconds\n",
      "FACES Test Accuracy with 360 samples: 0.8533\n",
      "Training Time: 16.45 seconds\n",
      "\n",
      "Complete Classification Results:\n",
      "Model  Samples  Data %  Training Time  Test Accuracy  Validation Accuracy  Epoch\n",
      "Digit      100    10.0         9.5390         0.6320               0.6120      1\n",
      "Digit      200    20.0         7.2784         0.6900               0.6940      2\n",
      "Digit      300    30.0         8.9538         0.7200               0.7300      3\n",
      "Digit      400    40.0        12.7258         0.7560               0.7580      4\n",
      "Digit      500    50.0        14.0393         0.7480               0.7720      5\n",
      "Digit      600    60.0        22.7225         0.7580               0.7900      6\n",
      "Digit      700    70.0        18.2720         0.7540               0.7880      7\n",
      "Digit      800    80.0        19.4093         0.7820               0.8020      8\n",
      "Digit      900    90.0        21.4259         0.8080               0.7840      9\n",
      "Digit     1000   100.0        24.4544         0.7920               0.7960     10\n",
      " Face       45    10.0         4.5335         0.7867               0.7575     11\n",
      " Face       90    20.0        10.5350         0.8400               0.8439     12\n",
      " Face      135    30.0        10.9448         0.8133               0.8306     13\n",
      " Face      180    40.0        10.6640         0.7333               0.7542     14\n",
      " Face      225    50.0        11.7580         0.8067               0.7940     15\n",
      " Face      270    60.0        13.4606         0.8133               0.8239     16\n",
      " Face      315    70.0        14.6420         0.8533               0.8605     17\n",
      " Face      360    80.0        16.4481         0.8533               0.8605     18\n",
      "\n",
      " FACES: Training on 405 samples (90%)\n",
      "Epoch 0: Loss = 0.7015 | Train Acc = 0.5136 | Val Acc = 0.5183\n",
      "Epoch 100: Loss = 0.7011 | Train Acc = 0.5136 | Val Acc = 0.5183\n",
      "Epoch 200: Loss = 0.7010 | Train Acc = 0.5136 | Val Acc = 0.5183\n",
      "Epoch 300: Loss = 0.7003 | Train Acc = 0.5136 | Val Acc = 0.5183\n",
      "Epoch 400: Loss = 0.6185 | Train Acc = 0.8988 | Val Acc = 0.7209\n",
      "Epoch 500: Loss = 0.1278 | Train Acc = 1.0000 | Val Acc = 0.8771\n",
      "Epoch 600: Loss = 0.0814 | Train Acc = 1.0000 | Val Acc = 0.8671\n",
      "Epoch 700: Loss = 0.0486 | Train Acc = 1.0000 | Val Acc = 0.8638\n",
      "Epoch 800: Loss = 0.0388 | Train Acc = 1.0000 | Val Acc = 0.8571\n",
      "Epoch 900: Loss = 0.0329 | Train Acc = 1.0000 | Val Acc = 0.8538\n",
      "Epoch 999: Loss = 0.0341 | Train Acc = 1.0000 | Val Acc = 0.8538\n",
      "Final Test Accuracy: 0.8667\n",
      "Training Time: 16.49 seconds\n",
      "FACES Test Accuracy with 405 samples: 0.8667\n",
      "Training Time: 16.49 seconds\n",
      "\n",
      "Complete Classification Results:\n",
      "Model  Samples  Data %  Training Time  Test Accuracy  Validation Accuracy  Epoch\n",
      "Digit      100    10.0         9.5390         0.6320               0.6120      1\n",
      "Digit      200    20.0         7.2784         0.6900               0.6940      2\n",
      "Digit      300    30.0         8.9538         0.7200               0.7300      3\n",
      "Digit      400    40.0        12.7258         0.7560               0.7580      4\n",
      "Digit      500    50.0        14.0393         0.7480               0.7720      5\n",
      "Digit      600    60.0        22.7225         0.7580               0.7900      6\n",
      "Digit      700    70.0        18.2720         0.7540               0.7880      7\n",
      "Digit      800    80.0        19.4093         0.7820               0.8020      8\n",
      "Digit      900    90.0        21.4259         0.8080               0.7840      9\n",
      "Digit     1000   100.0        24.4544         0.7920               0.7960     10\n",
      " Face       45    10.0         4.5335         0.7867               0.7575     11\n",
      " Face       90    20.0        10.5350         0.8400               0.8439     12\n",
      " Face      135    30.0        10.9448         0.8133               0.8306     13\n",
      " Face      180    40.0        10.6640         0.7333               0.7542     14\n",
      " Face      225    50.0        11.7580         0.8067               0.7940     15\n",
      " Face      270    60.0        13.4606         0.8133               0.8239     16\n",
      " Face      315    70.0        14.6420         0.8533               0.8605     17\n",
      " Face      360    80.0        16.4481         0.8533               0.8605     18\n",
      " Face      405    90.0        16.4941         0.8667               0.8771     19\n",
      "\n",
      " FACES: Training on 451 samples (100%)\n",
      "Epoch 0: Loss = 0.7007 | Train Acc = 0.5188 | Val Acc = 0.5183\n",
      "Epoch 100: Loss = 0.6999 | Train Acc = 0.5188 | Val Acc = 0.5183\n",
      "Epoch 200: Loss = 0.6998 | Train Acc = 0.5188 | Val Acc = 0.5183\n",
      "Epoch 300: Loss = 0.6991 | Train Acc = 0.5188 | Val Acc = 0.5183\n",
      "Epoch 400: Loss = 0.6363 | Train Acc = 0.8537 | Val Acc = 0.7110\n",
      "Epoch 500: Loss = 0.1100 | Train Acc = 1.0000 | Val Acc = 0.8870\n",
      "Epoch 600: Loss = 0.0740 | Train Acc = 1.0000 | Val Acc = 0.8738\n",
      "Epoch 700: Loss = 0.0391 | Train Acc = 1.0000 | Val Acc = 0.8671\n",
      "Epoch 800: Loss = 0.0437 | Train Acc = 1.0000 | Val Acc = 0.8671\n",
      "Epoch 900: Loss = 0.0292 | Train Acc = 1.0000 | Val Acc = 0.8638\n",
      "Epoch 999: Loss = 0.0297 | Train Acc = 1.0000 | Val Acc = 0.8638\n",
      "Final Test Accuracy: 0.8533\n",
      "Training Time: 18.77 seconds\n",
      "FACES Test Accuracy with 451 samples: 0.8533\n",
      "Training Time: 18.77 seconds\n",
      "\n",
      "Complete Classification Results:\n",
      "Model  Samples  Data %  Training Time  Test Accuracy  Validation Accuracy  Epoch\n",
      "Digit      100    10.0         9.5390         0.6320               0.6120      1\n",
      "Digit      200    20.0         7.2784         0.6900               0.6940      2\n",
      "Digit      300    30.0         8.9538         0.7200               0.7300      3\n",
      "Digit      400    40.0        12.7258         0.7560               0.7580      4\n",
      "Digit      500    50.0        14.0393         0.7480               0.7720      5\n",
      "Digit      600    60.0        22.7225         0.7580               0.7900      6\n",
      "Digit      700    70.0        18.2720         0.7540               0.7880      7\n",
      "Digit      800    80.0        19.4093         0.7820               0.8020      8\n",
      "Digit      900    90.0        21.4259         0.8080               0.7840      9\n",
      "Digit     1000   100.0        24.4544         0.7920               0.7960     10\n",
      " Face       45    10.0         4.5335         0.7867               0.7575     11\n",
      " Face       90    20.0        10.5350         0.8400               0.8439     12\n",
      " Face      135    30.0        10.9448         0.8133               0.8306     13\n",
      " Face      180    40.0        10.6640         0.7333               0.7542     14\n",
      " Face      225    50.0        11.7580         0.8067               0.7940     15\n",
      " Face      270    60.0        13.4606         0.8133               0.8239     16\n",
      " Face      315    70.0        14.6420         0.8533               0.8605     17\n",
      " Face      360    80.0        16.4481         0.8533               0.8605     18\n",
      " Face      405    90.0        16.4941         0.8667               0.8771     19\n",
      " Face      451   100.0        18.7724         0.8533               0.8870     20\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing neural net on face data\")\n",
    "\n",
    "# Load and process face data\n",
    "X_face_train_raw, y_face_train_raw = load_face_dataset(face_train_data_file, face_train_label_file, size=NUM_FACE_TRAINING)\n",
    "X_face_val_raw, y_face_val_raw     = load_face_dataset(face_val_data_file, face_val_label_file, size=NUM_FACE_VALIDATION)\n",
    "X_face_test_raw, y_face_test_raw   = load_face_dataset(face_test_data_file, face_test_label_file, size=NUM_FACE_TESTING)\n",
    "\n",
    "X_face_train = np.array(X_face_train_raw).T\n",
    "X_face_val   = np.array(X_face_val_raw).T\n",
    "X_face_test  = np.array(X_face_test_raw).T\n",
    "\n",
    "y_face_train = one_hot_encode_face(y_face_train_raw)\n",
    "y_face_val   = one_hot_encode_face(y_face_val_raw)\n",
    "y_face_test  = one_hot_encode_face(y_face_test_raw)\n",
    "\n",
    "# Train on increasing percentages of FACE data \n",
    "percentages = [0.1 * i for i in range(1, 11)]  # 10% to 100%\n",
    "total_face_samples = X_face_train.shape[1]\n",
    "\n",
    "for pct in percentages:\n",
    "    n = int(pct * total_face_samples)\n",
    "\n",
    "    X_subset = X_face_train[:, :n]\n",
    "    y_subset = y_face_train[:, :n]\n",
    "\n",
    "    print(f\"\\n FACES: Training on {n} samples ({int(pct * 100)}%)\")\n",
    "\n",
    "    trained_params, train_time = train_neural_net_face(\n",
    "        X_subset, y_subset,\n",
    "        X_face_test, y_face_test,\n",
    "        input_size=4200, h1=32, h2=16, output_size=2,\n",
    "        epochs=1000, lr=0.1,\n",
    "        X_val=X_face_val, y_val=y_face_val,\n",
    "        early_stopping=True, patience=10,\n",
    "        dropout_rate=0.5,\n",
    "        lambda_reg=0.5\n",
    "    )\n",
    "\n",
    "    # Get predictions and accuracies\n",
    "    test_preds = predict_nn_face(X_face_test, trained_params)\n",
    "    test_acc = evaluate(test_preds, np.argmax(y_face_test, axis=0))\n",
    "    \n",
    "    # Get validation accuracy\n",
    "    val_preds = predict_nn_face(X_face_val, trained_params)\n",
    "    val_acc = evaluate(val_preds, np.argmax(y_face_val, axis=0))\n",
    "    \n",
    "    # Store results in dictionary\n",
    "    batch_results = {\n",
    "        'Model': 'Face',\n",
    "        'Samples': n,\n",
    "        'Data %': pct * 100,\n",
    "        'Training Time': train_time,\n",
    "        'Test Accuracy': test_acc,\n",
    "        'Validation Accuracy': val_acc,\n",
    "        'Epoch': len(training_data) + 1\n",
    "    }\n",
    "    \n",
    "    # Append to training data list\n",
    "    training_data.append(batch_results)\n",
    "    \n",
    "    # Print current results\n",
    "    print(f\"FACES Test Accuracy with {n} samples: {test_acc:.4f}\")\n",
    "    print(f\"Training Time: {train_time:.2f} seconds\")\n",
    "\n",
    "    # Update DataFrame with all results\n",
    "    complete_df = pd.DataFrame(training_data)\n",
    "    \n",
    "    # Display summary of all results\n",
    "    print(\"\\nComplete Classification Results:\")\n",
    "    print(complete_df.round(4).to_string(index=False))\n",
    "\n",
    "# Save final results to CSV\n",
    "complete_df.to_csv('neural_network_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fe605920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_performance(df, output_dir='Charts-and-Graphs/Part_B'):\n",
    "    # Create output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    else:\n",
    "        # Remove old PDF files\n",
    "        for file in os.listdir(output_dir):\n",
    "            if file.endswith('.pdf') and file.startswith('partB_'):\n",
    "                os.remove(os.path.join(output_dir, file))\n",
    "\n",
    "    # Export classification tables\n",
    "    with PdfPages(f'{output_dir}/partB_classification_tables.pdf') as pdf:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.suptitle('Neural Network Results - Part B', fontsize=14, y=1.05)\n",
    "        plt.axis('tight')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        summary = df.groupby('Model')[['Test Accuracy', 'Validation Accuracy', 'Training Time']].mean()\n",
    "        table_data = [[row_name] + [f\"{val:.4f}\" for val in row] \n",
    "                     for row_name, row in zip(summary.index, summary.values)]\n",
    "        \n",
    "        table = plt.table(\n",
    "            cellText=table_data,\n",
    "            colLabels=['Model', 'Avg Test Acc', 'Avg Validation Acc', 'Avg Time (s)'],\n",
    "            loc='center',\n",
    "            cellLoc='center'\n",
    "        )\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(9)\n",
    "        table.scale(1.2, 1.5)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        pdf.savefig(bbox_inches='tight', pad_inches=0.5)\n",
    "        plt.close()\n",
    "\n",
    "    # Export learning curves\n",
    "    with PdfPages(f'{output_dir}/partB_learning_curves.pdf') as pdf:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        for model in ['Digit', 'Face']:\n",
    "            model_data = df[df['Model'] == model]\n",
    "            plt.plot(model_data['Data %'], \n",
    "                    model_data['Test Accuracy'], \n",
    "                    'b.-' if model == 'Digit' else 'r.-',\n",
    "                    label=f'{model} Test',\n",
    "                    linewidth=2, markersize=8)\n",
    "            plt.plot(model_data['Data %'], \n",
    "                    model_data['Validation Accuracy'], \n",
    "                    'b--' if model == 'Digit' else 'r--',\n",
    "                    label=f'{model} Validation',\n",
    "                    linewidth=2, markersize=8)\n",
    "        plt.xlabel('Percentage of Training Data', fontsize=12)\n",
    "        plt.ylabel('Accuracy', fontsize=12)\n",
    "        plt.title('Neural Network Learning Curves - Part B', fontsize=14)\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.legend(fontsize=10)\n",
    "        plt.tight_layout()\n",
    "        pdf.savefig(bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    # Export training times\n",
    "    with PdfPages(f'{output_dir}/partB_training_times.pdf') as pdf:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        for model in ['Digit', 'Face']:\n",
    "            model_data = df[df['Model'] == model]\n",
    "            plt.plot(model_data['Data %'], \n",
    "                    model_data['Training Time'], \n",
    "                    'b.-' if model == 'Digit' else 'r.-',\n",
    "                    label=f'{model} Recognition',\n",
    "                    linewidth=2, markersize=8)\n",
    "        plt.xlabel('Percentage of Training Data', fontsize=12)\n",
    "        plt.ylabel('Training Time (seconds)', fontsize=12)\n",
    "        plt.title('Neural Network Training Times - Part B', fontsize=14)\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.legend(fontsize=10)\n",
    "        plt.tight_layout()\n",
    "        pdf.savefig(bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    # Print summary statistics\n",
    "    print(\"\\nNeural Network Part B - Performance Summary:\")\n",
    "    for model in ['Digit', 'Face']:\n",
    "        model_data = df[df['Model'] == model]\n",
    "        print(f\"\\n{model} Recognition:\")\n",
    "        print(f\"Average Training Time: {model_data['Training Time'].mean():.2f} ± {model_data['Training Time'].std():.2f} seconds\")\n",
    "        print(f\"Average Test Error: {(1 - model_data['Test Accuracy']).mean():.4f} ± {(1 - model_data['Test Accuracy']).std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be3c273a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neural Network Part B - Performance Summary:\n",
      "\n",
      "Digit Recognition:\n",
      "Average Training Time: 15.88 ± 6.19 seconds\n",
      "Average Test Error: 0.2560 ± 0.0520\n",
      "\n",
      "Face Recognition:\n",
      "Average Training Time: 12.83 ± 4.07 seconds\n",
      "Average Test Error: 0.1780 ± 0.0405\n",
      "\n",
      "Generating summary statistics...\n",
      "\n",
      "Performance Statistics:\n",
      "      Training Time         Test Accuracy         Validation Accuracy        \n",
      "               mean     std          mean     std                mean     std\n",
      "Model                                                                        \n",
      "Digit       15.8820  6.1894         0.744  0.0520              0.7526  0.0597\n",
      "Face        12.8252  4.0689         0.822  0.0405              0.8289  0.0470\n",
      "\n",
      "Error Rate Statistics:\n",
      "                                     Test Accuracy  \\\n",
      "Model                                                \n",
      "Digit                 (0.256, 0.05200000000000002)   \n",
      "Face   (0.17799999999999994, 0.040496913462633205)   \n",
      "\n",
      "                              Validation Accuracy  \n",
      "Model                                              \n",
      "Digit  (0.24740000000000006, 0.05970334068449513)  \n",
      "Face   (0.17109634551495012, 0.04696425860163903)  \n"
     ]
    }
   ],
   "source": [
    "# Run the analysis on the complete DataFrame\n",
    "analyze_performance(complete_df)\n",
    "\n",
    "# Create and print the summary tables\n",
    "print(\"\\nGenerating summary statistics...\")\n",
    "performance_stats = complete_df.groupby('Model')[['Training Time', 'Test Accuracy', 'Validation Accuracy']].agg(['mean', 'std'])\n",
    "error_stats = complete_df.groupby('Model').agg({\n",
    "    'Test Accuracy': lambda x: (1 - x.mean(), x.std()),\n",
    "    'Validation Accuracy': lambda x: (1 - x.mean(), x.std())\n",
    "})\n",
    "\n",
    "print(\"\\nPerformance Statistics:\")\n",
    "print(performance_stats.round(4))\n",
    "print(\"\\nError Rate Statistics:\")\n",
    "print(error_stats.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323cc778",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
