{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "52ce080d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip data\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "if not os.path.exists(\"data\"):\n",
    "    with zipfile.ZipFile(\"data.zip\", \"r\") as zip_ref:\n",
    "        zip_ref.extractall(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1efaf3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "NUM_EPOCHS = 5\n",
    "NUM_TRAINING = 1000\n",
    "NUM_TESTING = 500\n",
    "NUM_VALIDATION = 500\n",
    "\n",
    "NUM_FACE_TRAINING = 3000\n",
    "NUM_FACE_VALIDATION = 800\n",
    "NUM_FACE_TESTING = 800\n",
    "\n",
    "\n",
    "IMAGE_HEIGHT = 28\n",
    "IMAGE_WIDTH = 28\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ae6c81b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepaths\n",
    "train_data_file = \"data/digitdata/trainingimages\"\n",
    "train_label_file = \"data/digitdata/traininglabels\"\n",
    "val_data_file = \"data/digitdata/validationimages\"\n",
    "val_label_file = \"data/digitdata/validationlabels\"\n",
    "test_data_file = \"data/digitdata/testimages\"\n",
    "test_label_file = \"data/digitdata/testlabels\"\n",
    "\n",
    "\n",
    "\n",
    "face_train_data_file = \"data/facedata/facedatatrain\"\n",
    "face_train_label_file = \"data/facedata/facedatatrainlabels\"\n",
    "face_val_data_file   = \"data/facedata/facedatavalidation\"\n",
    "face_val_label_file  = \"data/facedata/facedatavalidationlabels\"\n",
    "face_test_data_file  = \"data/facedata/facedatatest\"\n",
    "face_test_label_file = \"data/facedata/facedatatestlabels\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8e1f45af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53324bb2",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fca12b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_data_file(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    return [line.rstrip(\"\\n\") for line in lines]\n",
    "\n",
    "def extract_features(raw_data):\n",
    "    features = []\n",
    "    for i in range(0, len(raw_data), 28):\n",
    "        image = raw_data[i:i+28]\n",
    "        feature = [1 if ch != ' ' else 0 for row in image for ch in row]\n",
    "        features.append(feature)\n",
    "    return features\n",
    "\n",
    "def read_labels(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    return [int(line.strip()) for line in lines]\n",
    "\n",
    "def load_dataset(data_file, label_file, size=None):\n",
    "    raw_data = read_data_file(data_file)\n",
    "    raw_labels = read_labels(label_file)\n",
    "\n",
    "    features = extract_features(raw_data)\n",
    "    if size is not None:\n",
    "        combined = list(zip(features, raw_labels))\n",
    "        random.shuffle(combined)\n",
    "        features, raw_labels = zip(*combined[:size])\n",
    "\n",
    "    return list(features), list(raw_labels)\n",
    "\n",
    "def one_hot_encode(y, num_classes=10):\n",
    "    encoded = np.zeros((num_classes, len(y)))\n",
    "    for idx, val in enumerate(y):\n",
    "        encoded[val][idx] = 1\n",
    "    return encoded\n",
    "\n",
    "def evaluate(predictions, labels):\n",
    "    correct = sum(p == t for p, t in zip(predictions, labels))\n",
    "    return correct / len(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3113e73",
   "metadata": {},
   "source": [
    "## Neural Network Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d869892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Activation functions\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def relu_derivative(z):\n",
    "    return (z > 0).astype(float)\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def sigmoid_derivative(a):\n",
    "    return a * (1 - a)\n",
    "\n",
    "# Initialize weights and biases\n",
    "def initialize_parameters(input_size, hidden1_size, hidden2_size, output_size):\n",
    "    np.random.seed(42)\n",
    "    return {\n",
    "        'W1': np.random.randn(hidden1_size, input_size) * 0.01,\n",
    "        'b1': np.zeros((hidden1_size, 1)),\n",
    "        'W2': np.random.randn(hidden2_size, hidden1_size) * 0.01,\n",
    "        'b2': np.zeros((hidden2_size, 1)),\n",
    "        'W3': np.random.randn(output_size, hidden2_size) * 0.01,\n",
    "        'b3': np.zeros((output_size, 1))\n",
    "    }\n",
    "\n",
    "# Forward pass\n",
    "def forward_propagation(X, parameters):\n",
    "    W1, b1 = parameters['W1'], parameters['b1']\n",
    "    W2, b2 = parameters['W2'], parameters['b2']\n",
    "    W3, b3 = parameters['W3'], parameters['b3']\n",
    "\n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = relu(Z1)\n",
    "\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = relu(Z2)\n",
    "\n",
    "    Z3 = np.dot(W3, A2) + b3\n",
    "    A3 = sigmoid(Z3)\n",
    "\n",
    "    cache = (Z1, A1, Z2, A2, Z3, A3)\n",
    "    return A3, cache\n",
    "\n",
    "# Loss\n",
    "def compute_loss(Y_hat, Y):\n",
    "    m = Y.shape[1]\n",
    "    return -np.sum(Y * np.log(Y_hat + 1e-8) + (1 - Y) * np.log(1 - Y_hat + 1e-8)) / m\n",
    "\n",
    "# Backward pass\n",
    "def backward_propagation(X, Y, parameters, cache):\n",
    "    m = X.shape[1]\n",
    "    W2, W3 = parameters['W2'], parameters['W3']\n",
    "    Z1, A1, Z2, A2, Z3, A3 = cache\n",
    "\n",
    "    dZ3 = A3 - Y\n",
    "    dW3 = (1/m) * np.dot(dZ3, A2.T)\n",
    "    db3 = (1/m) * np.sum(dZ3, axis=1, keepdims=True)\n",
    "\n",
    "    dA2 = np.dot(W3.T, dZ3)\n",
    "    dZ2 = dA2 * relu_derivative(Z2)\n",
    "    dW2 = (1/m) * np.dot(dZ2, A1.T)\n",
    "    db2 = (1/m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "\n",
    "    dA1 = np.dot(W2.T, dZ2)\n",
    "    dZ1 = dA1 * relu_derivative(Z1)\n",
    "    dW1 = (1/m) * np.dot(dZ1, X.T)\n",
    "    db1 = (1/m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "\n",
    "    return {\n",
    "        'dW1': dW1, 'db1': db1,\n",
    "        'dW2': dW2, 'db2': db2,\n",
    "        'dW3': dW3, 'db3': db3\n",
    "    }\n",
    "\n",
    "# Gradient descent update\n",
    "def update_parameters(params, grads, lr):\n",
    "    for key in params:\n",
    "        params[key] -= lr * grads['d' + key]\n",
    "    return params\n",
    "\n",
    "# Prediction\n",
    "def predict_nn(X, parameters):\n",
    "    Y_hat, _ = forward_propagation(X, parameters)\n",
    "    return np.argmax(Y_hat, axis=0)\n",
    "\n",
    "# Training loop\n",
    "def train_neural_net(X_train, y_train, X_test, y_test,\n",
    "                     input_size, h1, h2, output_size,\n",
    "                     epochs=1000, lr=0.1, print_loss=True,\n",
    "                     X_val=None, y_val=None, early_stopping=False, patience=10):\n",
    "    \n",
    "    parameters = initialize_parameters(input_size, h1, h2, output_size)\n",
    "    best_params = None\n",
    "    best_val_acc = 0\n",
    "    val_acc_counter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Forward and backpropagation\n",
    "        Y_hat, cache = forward_propagation(X_train, parameters)\n",
    "        loss = compute_loss(Y_hat, y_train)\n",
    "        grads = backward_propagation(X_train, y_train, parameters, cache)\n",
    "        parameters = update_parameters(parameters, grads, lr)\n",
    "\n",
    "        # Check performance every 100 epochs\n",
    "        if epoch % 100 == 0 or epoch == epochs - 1:\n",
    "            train_preds = predict_nn(X_train, parameters)\n",
    "            train_acc = evaluate(train_preds, np.argmax(y_train, axis=0))\n",
    "            \n",
    "            if X_val is not None and y_val is not None:\n",
    "                val_preds = predict_nn(X_val, parameters)\n",
    "                val_acc = evaluate(val_preds, np.argmax(y_val, axis=0))\n",
    "\n",
    "                if print_loss:\n",
    "                    print(f\"Epoch {epoch}: Loss = {loss:.4f} | Train Acc = {train_acc:.4f} | Val Acc = {val_acc:.4f}\")\n",
    "\n",
    "                # Save best model\n",
    "                if val_acc > best_val_acc:\n",
    "                    best_val_acc = val_acc\n",
    "                    best_params = {k: v.copy() for k, v in parameters.items()}\n",
    "                    val_acc_counter = 0\n",
    "                else:\n",
    "                    val_acc_counter += 1\n",
    "                    if early_stopping and val_acc_counter >= patience:\n",
    "                        print(\"Early stopping triggered.\")\n",
    "                        break\n",
    "            else:\n",
    "                if print_loss:\n",
    "                    print(f\"Epoch {epoch}: Loss = {loss:.4f} | Train Acc = {train_acc:.4f}\")\n",
    "\n",
    "    final_params = best_params if best_params is not None else parameters\n",
    "\n",
    "    # Final test evaluation\n",
    "    test_preds = predict_nn(X_test, final_params)\n",
    "    test_acc = evaluate(test_preds, np.argmax(y_test, axis=0))\n",
    "    print(f\"Final Test Accuracy: {test_acc:.4f}\")\n",
    "    return final_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87085246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing neural net on digit data\n",
      "\n",
      " DIGITS: Training on 100 samples (10%)\n",
      "Epoch 0: Loss = 6.9313 | Train Acc = 0.1300 | Val Acc = 0.1180\n",
      "Epoch 100: Loss = 3.2307 | Train Acc = 0.1300 | Val Acc = 0.1280\n",
      "Epoch 200: Loss = 3.1547 | Train Acc = 0.2200 | Val Acc = 0.2280\n",
      "Epoch 300: Loss = 2.2593 | Train Acc = 0.5700 | Val Acc = 0.3740\n",
      "Epoch 400: Loss = 0.6183 | Train Acc = 0.9600 | Val Acc = 0.6280\n",
      "Epoch 500: Loss = 0.0800 | Train Acc = 1.0000 | Val Acc = 0.6220\n",
      "Epoch 600: Loss = 0.0308 | Train Acc = 1.0000 | Val Acc = 0.6180\n",
      "Epoch 700: Loss = 0.0174 | Train Acc = 1.0000 | Val Acc = 0.6180\n",
      "Epoch 800: Loss = 0.0116 | Train Acc = 1.0000 | Val Acc = 0.6180\n",
      "Epoch 900: Loss = 0.0085 | Train Acc = 1.0000 | Val Acc = 0.6180\n",
      "Epoch 999: Loss = 0.0067 | Train Acc = 1.0000 | Val Acc = 0.6180\n",
      "Final Test Accuracy: 0.5980\n",
      "DIGITS Test Accuracy with 100 samples: 0.5980\n",
      "\n",
      " DIGITS: Training on 200 samples (20%)\n",
      "Epoch 0: Loss = 6.9313 | Train Acc = 0.1350 | Val Acc = 0.1180\n",
      "Epoch 100: Loss = 3.2361 | Train Acc = 0.1400 | Val Acc = 0.1420\n",
      "Epoch 200: Loss = 3.1209 | Train Acc = 0.1950 | Val Acc = 0.1680\n",
      "Epoch 300: Loss = 2.2724 | Train Acc = 0.5700 | Val Acc = 0.3980\n",
      "Epoch 400: Loss = 1.1257 | Train Acc = 0.8900 | Val Acc = 0.6180\n",
      "Epoch 500: Loss = 0.3539 | Train Acc = 0.9800 | Val Acc = 0.7000\n",
      "Epoch 600: Loss = 0.0997 | Train Acc = 1.0000 | Val Acc = 0.6980\n",
      "Epoch 700: Loss = 0.0430 | Train Acc = 1.0000 | Val Acc = 0.7080\n",
      "Epoch 800: Loss = 0.0246 | Train Acc = 1.0000 | Val Acc = 0.7100\n",
      "Epoch 900: Loss = 0.0165 | Train Acc = 1.0000 | Val Acc = 0.7100\n",
      "Epoch 999: Loss = 0.0121 | Train Acc = 1.0000 | Val Acc = 0.7080\n",
      "Final Test Accuracy: 0.6820\n",
      "DIGITS Test Accuracy with 200 samples: 0.6820\n",
      "\n",
      " DIGITS: Training on 300 samples (30%)\n",
      "Epoch 0: Loss = 6.9313 | Train Acc = 0.0867 | Val Acc = 0.0820\n",
      "Epoch 100: Loss = 3.2642 | Train Acc = 0.1033 | Val Acc = 0.0980\n",
      "Epoch 200: Loss = 3.2269 | Train Acc = 0.1167 | Val Acc = 0.1320\n",
      "Epoch 300: Loss = 2.1453 | Train Acc = 0.6000 | Val Acc = 0.5500\n",
      "Epoch 400: Loss = 1.1371 | Train Acc = 0.8733 | Val Acc = 0.6980\n",
      "Epoch 500: Loss = 0.4959 | Train Acc = 0.9700 | Val Acc = 0.7400\n",
      "Epoch 600: Loss = 0.1781 | Train Acc = 0.9900 | Val Acc = 0.7600\n",
      "Epoch 700: Loss = 0.0709 | Train Acc = 1.0000 | Val Acc = 0.7580\n",
      "Epoch 800: Loss = 0.0375 | Train Acc = 1.0000 | Val Acc = 0.7640\n",
      "Epoch 900: Loss = 0.0239 | Train Acc = 1.0000 | Val Acc = 0.7680\n",
      "Epoch 999: Loss = 0.0170 | Train Acc = 1.0000 | Val Acc = 0.7660\n",
      "Final Test Accuracy: 0.7180\n",
      "DIGITS Test Accuracy with 300 samples: 0.7180\n",
      "\n",
      " DIGITS: Training on 400 samples (40%)\n",
      "Epoch 0: Loss = 6.9313 | Train Acc = 0.0825 | Val Acc = 0.1060\n",
      "Epoch 100: Loss = 3.2646 | Train Acc = 0.1250 | Val Acc = 0.1380\n",
      "Epoch 200: Loss = 3.2371 | Train Acc = 0.1375 | Val Acc = 0.1340\n",
      "Epoch 300: Loss = 2.0887 | Train Acc = 0.6600 | Val Acc = 0.6200\n",
      "Epoch 400: Loss = 1.2410 | Train Acc = 0.8150 | Val Acc = 0.7000\n",
      "Epoch 500: Loss = 0.6382 | Train Acc = 0.9200 | Val Acc = 0.7460\n",
      "Epoch 600: Loss = 0.2952 | Train Acc = 0.9850 | Val Acc = 0.7540\n",
      "Epoch 700: Loss = 0.1269 | Train Acc = 0.9950 | Val Acc = 0.7580\n",
      "Epoch 800: Loss = 0.0596 | Train Acc = 1.0000 | Val Acc = 0.7660\n",
      "Epoch 900: Loss = 0.0348 | Train Acc = 1.0000 | Val Acc = 0.7740\n",
      "Epoch 999: Loss = 0.0234 | Train Acc = 1.0000 | Val Acc = 0.7760\n",
      "Final Test Accuracy: 0.7420\n",
      "DIGITS Test Accuracy with 400 samples: 0.7420\n",
      "\n",
      " DIGITS: Training on 500 samples (50%)\n",
      "Epoch 0: Loss = 6.9313 | Train Acc = 0.1240 | Val Acc = 0.1200\n",
      "Epoch 100: Loss = 3.2592 | Train Acc = 0.1220 | Val Acc = 0.1180\n",
      "Epoch 200: Loss = 3.2271 | Train Acc = 0.1220 | Val Acc = 0.1180\n",
      "Epoch 300: Loss = 2.0672 | Train Acc = 0.6480 | Val Acc = 0.6220\n",
      "Epoch 400: Loss = 1.1842 | Train Acc = 0.8200 | Val Acc = 0.7300\n",
      "Epoch 500: Loss = 0.6249 | Train Acc = 0.9280 | Val Acc = 0.7900\n",
      "Epoch 600: Loss = 0.3299 | Train Acc = 0.9760 | Val Acc = 0.7980\n",
      "Epoch 700: Loss = 0.1670 | Train Acc = 0.9920 | Val Acc = 0.8020\n",
      "Epoch 800: Loss = 0.0834 | Train Acc = 0.9980 | Val Acc = 0.8040\n",
      "Epoch 900: Loss = 0.0474 | Train Acc = 1.0000 | Val Acc = 0.8080\n",
      "Epoch 999: Loss = 0.0311 | Train Acc = 1.0000 | Val Acc = 0.8080\n",
      "Final Test Accuracy: 0.7740\n",
      "DIGITS Test Accuracy with 500 samples: 0.7740\n",
      "\n",
      " DIGITS: Training on 600 samples (60%)\n",
      "Epoch 0: Loss = 6.9313 | Train Acc = 0.1267 | Val Acc = 0.1120\n",
      "Epoch 100: Loss = 3.2633 | Train Acc = 0.1233 | Val Acc = 0.1180\n",
      "Epoch 200: Loss = 3.2268 | Train Acc = 0.1317 | Val Acc = 0.1380\n",
      "Epoch 300: Loss = 2.1695 | Train Acc = 0.5850 | Val Acc = 0.5500\n",
      "Epoch 400: Loss = 1.2646 | Train Acc = 0.7967 | Val Acc = 0.7240\n",
      "Epoch 500: Loss = 0.7680 | Train Acc = 0.9100 | Val Acc = 0.7700\n",
      "Epoch 600: Loss = 0.4771 | Train Acc = 0.9583 | Val Acc = 0.7800\n",
      "Epoch 700: Loss = 0.2788 | Train Acc = 0.9867 | Val Acc = 0.7800\n",
      "Epoch 800: Loss = 0.1564 | Train Acc = 0.9950 | Val Acc = 0.7920\n",
      "Epoch 900: Loss = 0.0888 | Train Acc = 0.9983 | Val Acc = 0.8000\n",
      "Epoch 999: Loss = 0.0524 | Train Acc = 1.0000 | Val Acc = 0.7960\n",
      "Final Test Accuracy: 0.7640\n",
      "DIGITS Test Accuracy with 600 samples: 0.7640\n",
      "\n",
      " DIGITS: Training on 700 samples (70%)\n",
      "Epoch 0: Loss = 6.9313 | Train Acc = 0.1243 | Val Acc = 0.1140\n",
      "Epoch 100: Loss = 3.2642 | Train Acc = 0.1243 | Val Acc = 0.1180\n",
      "Epoch 200: Loss = 3.2299 | Train Acc = 0.1271 | Val Acc = 0.1240\n",
      "Epoch 300: Loss = 2.2374 | Train Acc = 0.5757 | Val Acc = 0.5280\n",
      "Epoch 400: Loss = 1.3095 | Train Acc = 0.7829 | Val Acc = 0.7100\n",
      "Epoch 500: Loss = 0.8057 | Train Acc = 0.9043 | Val Acc = 0.7900\n",
      "Epoch 600: Loss = 0.4875 | Train Acc = 0.9500 | Val Acc = 0.8060\n",
      "Epoch 700: Loss = 0.2864 | Train Acc = 0.9814 | Val Acc = 0.8180\n",
      "Epoch 800: Loss = 0.1566 | Train Acc = 0.9943 | Val Acc = 0.8140\n",
      "Epoch 900: Loss = 0.0905 | Train Acc = 0.9986 | Val Acc = 0.8160\n",
      "Epoch 999: Loss = 0.0558 | Train Acc = 0.9986 | Val Acc = 0.8140\n",
      "Final Test Accuracy: 0.7900\n",
      "DIGITS Test Accuracy with 700 samples: 0.7900\n",
      "\n",
      " DIGITS: Training on 800 samples (80%)\n",
      "Epoch 0: Loss = 6.9313 | Train Acc = 0.1163 | Val Acc = 0.1120\n",
      "Epoch 100: Loss = 3.2658 | Train Acc = 0.1187 | Val Acc = 0.1180\n",
      "Epoch 200: Loss = 3.2372 | Train Acc = 0.1200 | Val Acc = 0.1180\n",
      "Epoch 300: Loss = 2.1726 | Train Acc = 0.6138 | Val Acc = 0.5700\n",
      "Epoch 400: Loss = 1.3109 | Train Acc = 0.7863 | Val Acc = 0.7200\n",
      "Epoch 500: Loss = 0.7989 | Train Acc = 0.8950 | Val Acc = 0.7840\n",
      "Epoch 600: Loss = 0.4972 | Train Acc = 0.9513 | Val Acc = 0.8140\n",
      "Epoch 700: Loss = 0.2938 | Train Acc = 0.9788 | Val Acc = 0.8240\n",
      "Epoch 800: Loss = 0.1709 | Train Acc = 0.9912 | Val Acc = 0.8240\n",
      "Epoch 900: Loss = 0.0994 | Train Acc = 0.9975 | Val Acc = 0.8260\n",
      "Epoch 999: Loss = 0.0614 | Train Acc = 0.9988 | Val Acc = 0.8260\n",
      "Final Test Accuracy: 0.7900\n",
      "DIGITS Test Accuracy with 800 samples: 0.7900\n",
      "\n",
      " DIGITS: Training on 900 samples (90%)\n",
      "Epoch 0: Loss = 6.9313 | Train Acc = 0.1556 | Val Acc = 0.1740\n",
      "Epoch 100: Loss = 3.2648 | Train Acc = 0.1156 | Val Acc = 0.1040\n",
      "Epoch 200: Loss = 3.2352 | Train Acc = 0.1544 | Val Acc = 0.1320\n",
      "Epoch 300: Loss = 2.1939 | Train Acc = 0.5844 | Val Acc = 0.5440\n",
      "Epoch 400: Loss = 1.3176 | Train Acc = 0.7900 | Val Acc = 0.7220\n",
      "Epoch 500: Loss = 0.7821 | Train Acc = 0.9033 | Val Acc = 0.7880\n",
      "Epoch 600: Loss = 0.5104 | Train Acc = 0.9456 | Val Acc = 0.8060\n",
      "Epoch 700: Loss = 0.3080 | Train Acc = 0.9733 | Val Acc = 0.8140\n",
      "Epoch 800: Loss = 0.1908 | Train Acc = 0.9889 | Val Acc = 0.8120\n",
      "Epoch 900: Loss = 0.1207 | Train Acc = 0.9944 | Val Acc = 0.8140\n",
      "Epoch 999: Loss = 0.0784 | Train Acc = 0.9978 | Val Acc = 0.8120\n",
      "Final Test Accuracy: 0.7960\n",
      "DIGITS Test Accuracy with 900 samples: 0.7960\n",
      "\n",
      " DIGITS: Training on 1000 samples (100%)\n",
      "Epoch 0: Loss = 6.9313 | Train Acc = 0.1200 | Val Acc = 0.1180\n",
      "Epoch 100: Loss = 3.2650 | Train Acc = 0.1150 | Val Acc = 0.1040\n",
      "Epoch 200: Loss = 3.2346 | Train Acc = 0.1290 | Val Acc = 0.1380\n",
      "Epoch 300: Loss = 2.1630 | Train Acc = 0.5750 | Val Acc = 0.5580\n",
      "Epoch 400: Loss = 1.3239 | Train Acc = 0.7730 | Val Acc = 0.7160\n",
      "Epoch 500: Loss = 0.8264 | Train Acc = 0.8880 | Val Acc = 0.7940\n",
      "Epoch 600: Loss = 0.5437 | Train Acc = 0.9350 | Val Acc = 0.8180\n",
      "Epoch 700: Loss = 0.3361 | Train Acc = 0.9730 | Val Acc = 0.8280\n",
      "Epoch 800: Loss = 0.2119 | Train Acc = 0.9910 | Val Acc = 0.8360\n",
      "Epoch 900: Loss = 0.1382 | Train Acc = 0.9910 | Val Acc = 0.8320\n",
      "Epoch 999: Loss = 0.0940 | Train Acc = 0.9970 | Val Acc = 0.8340\n",
      "Final Test Accuracy: 0.8080\n",
      "DIGITS Test Accuracy with 1000 samples: 0.8080\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing neural net on digit data\")\n",
    "\n",
    "X_train_raw, y_train_raw = load_dataset(train_data_file, train_label_file, size=NUM_TRAINING)\n",
    "X_val_raw, y_val_raw     = load_dataset(val_data_file, val_label_file, size=NUM_VALIDATION)\n",
    "X_test_raw, y_test_raw   = load_dataset(test_data_file, test_label_file, size=NUM_TESTING)\n",
    "\n",
    "X_train = np.array(X_train_raw).T\n",
    "X_val   = np.array(X_val_raw).T\n",
    "X_test  = np.array(X_test_raw).T\n",
    "\n",
    "y_train = one_hot_encode(y_train_raw)\n",
    "y_val   = one_hot_encode(y_val_raw)\n",
    "y_test  = one_hot_encode(y_test_raw)\n",
    "\n",
    "# Train on increasing percentages of DIGIT data \n",
    "percentages = [0.1 * i for i in range(1, 11)]  # 10% to 100%\n",
    "total_digit_samples = X_train.shape[1]\n",
    "\n",
    "digit_results = []\n",
    "\n",
    "for pct in percentages:\n",
    "    n = int(pct * total_digit_samples)\n",
    "    X_subset = X_train[:, :n]\n",
    "    y_subset = y_train[:, :n]\n",
    "\n",
    "    print(f\"\\n DIGITS: Training on {n} samples ({int(pct * 100)}%)\")\n",
    "    \n",
    "    trained_params = train_neural_net(\n",
    "        X_subset, y_subset,\n",
    "        X_test, y_test,\n",
    "        input_size=784, h1=128, h2=64, output_size=10,\n",
    "        epochs=1000, lr=0.1,\n",
    "        X_val=X_val, y_val=y_val,\n",
    "        early_stopping=True, patience=10\n",
    "    )\n",
    "\n",
    "    test_preds = predict_nn(X_test, trained_params)\n",
    "    test_acc = evaluate(test_preds, np.argmax(y_test, axis=0))\n",
    "    digit_results.append((n, test_acc))\n",
    "    print(f\"DIGITS Test Accuracy with {n} samples: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46f49a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing neural net on face data\n",
      "\n",
      " FACES: Training on 45 samples (10%)\n",
      "Epoch 0: Loss = 1.3863 | Train Acc = 0.5111 | Val Acc = 0.5133\n",
      "Epoch 100: Loss = 1.3851 | Train Acc = 0.5111 | Val Acc = 0.5133\n",
      "Epoch 200: Loss = 1.0757 | Train Acc = 1.0000 | Val Acc = 0.4933\n",
      "Epoch 300: Loss = 0.0199 | Train Acc = 1.0000 | Val Acc = 0.5067\n",
      "Epoch 400: Loss = 0.0109 | Train Acc = 1.0000 | Val Acc = 0.4867\n",
      "Epoch 500: Loss = 0.0076 | Train Acc = 1.0000 | Val Acc = 0.4933\n",
      "Epoch 600: Loss = 0.0056 | Train Acc = 1.0000 | Val Acc = 0.5000\n",
      "Epoch 700: Loss = 0.0044 | Train Acc = 1.0000 | Val Acc = 0.5000\n",
      "Epoch 800: Loss = 0.0035 | Train Acc = 1.0000 | Val Acc = 0.5067\n",
      "Epoch 900: Loss = 0.0028 | Train Acc = 1.0000 | Val Acc = 0.5067\n",
      "Epoch 999: Loss = 0.0024 | Train Acc = 1.0000 | Val Acc = 0.4933\n",
      "Early stopping triggered.\n",
      "Final Test Accuracy: 0.5133\n",
      "FACES Test Accuracy with 45 samples: 0.5133\n",
      "\n",
      " FACES: Training on 90 samples (20%)\n",
      "Epoch 0: Loss = 1.3863 | Train Acc = 0.5333 | Val Acc = 0.4867\n",
      "Epoch 100: Loss = 1.3816 | Train Acc = 0.5333 | Val Acc = 0.4867\n",
      "Epoch 200: Loss = 1.3790 | Train Acc = 0.5333 | Val Acc = 0.4867\n",
      "Epoch 300: Loss = 0.1319 | Train Acc = 1.0000 | Val Acc = 0.4933\n",
      "Epoch 400: Loss = 0.0131 | Train Acc = 1.0000 | Val Acc = 0.5133\n",
      "Epoch 500: Loss = 0.0078 | Train Acc = 1.0000 | Val Acc = 0.5133\n",
      "Epoch 600: Loss = 0.0058 | Train Acc = 1.0000 | Val Acc = 0.4867\n",
      "Epoch 700: Loss = 0.0047 | Train Acc = 1.0000 | Val Acc = 0.5000\n",
      "Epoch 800: Loss = 0.0039 | Train Acc = 1.0000 | Val Acc = 0.4933\n",
      "Epoch 900: Loss = 0.0033 | Train Acc = 1.0000 | Val Acc = 0.5000\n",
      "Epoch 999: Loss = 0.0028 | Train Acc = 1.0000 | Val Acc = 0.5000\n",
      "Final Test Accuracy: 0.5133\n",
      "FACES Test Accuracy with 90 samples: 0.5133\n",
      "\n",
      " FACES: Training on 135 samples (30%)\n",
      "Epoch 0: Loss = 1.3863 | Train Acc = 0.4889 | Val Acc = 0.5400\n",
      "Epoch 100: Loss = 1.3862 | Train Acc = 0.5037 | Val Acc = 0.5133\n",
      "Epoch 200: Loss = 1.3859 | Train Acc = 0.5037 | Val Acc = 0.5133\n",
      "Epoch 300: Loss = 1.3841 | Train Acc = 0.5037 | Val Acc = 0.5133\n",
      "Epoch 400: Loss = 0.7209 | Train Acc = 1.0000 | Val Acc = 0.5200\n",
      "Epoch 500: Loss = 0.0152 | Train Acc = 1.0000 | Val Acc = 0.5133\n",
      "Epoch 600: Loss = 0.0077 | Train Acc = 1.0000 | Val Acc = 0.5200\n",
      "Epoch 700: Loss = 0.0052 | Train Acc = 1.0000 | Val Acc = 0.5200\n",
      "Epoch 800: Loss = 0.0039 | Train Acc = 1.0000 | Val Acc = 0.5200\n",
      "Epoch 900: Loss = 0.0032 | Train Acc = 1.0000 | Val Acc = 0.5067\n",
      "Epoch 999: Loss = 0.0027 | Train Acc = 1.0000 | Val Acc = 0.5067\n",
      "Early stopping triggered.\n",
      "Final Test Accuracy: 0.5400\n",
      "FACES Test Accuracy with 135 samples: 0.5400\n",
      "\n",
      " FACES: Training on 180 samples (40%)\n",
      "Epoch 0: Loss = 1.3863 | Train Acc = 0.5167 | Val Acc = 0.5133\n",
      "Epoch 100: Loss = 1.3851 | Train Acc = 0.5167 | Val Acc = 0.5133\n",
      "Epoch 200: Loss = 1.3848 | Train Acc = 0.5167 | Val Acc = 0.5133\n",
      "Epoch 300: Loss = 1.3822 | Train Acc = 0.5167 | Val Acc = 0.5133\n",
      "Epoch 400: Loss = 0.6215 | Train Acc = 0.9944 | Val Acc = 0.5200\n",
      "Epoch 500: Loss = 0.0146 | Train Acc = 1.0000 | Val Acc = 0.5133\n",
      "Epoch 600: Loss = 0.0070 | Train Acc = 1.0000 | Val Acc = 0.5133\n",
      "Epoch 700: Loss = 0.0046 | Train Acc = 1.0000 | Val Acc = 0.5000\n",
      "Epoch 800: Loss = 0.0034 | Train Acc = 1.0000 | Val Acc = 0.5133\n",
      "Epoch 900: Loss = 0.0028 | Train Acc = 1.0000 | Val Acc = 0.5133\n",
      "Epoch 999: Loss = 0.0024 | Train Acc = 1.0000 | Val Acc = 0.5133\n",
      "Final Test Accuracy: 0.5200\n",
      "FACES Test Accuracy with 180 samples: 0.5200\n",
      "\n",
      " FACES: Training on 225 samples (50%)\n",
      "Epoch 0: Loss = 1.3863 | Train Acc = 0.5156 | Val Acc = 0.4933\n",
      "Epoch 100: Loss = 1.3862 | Train Acc = 0.5022 | Val Acc = 0.4867\n",
      "Epoch 200: Loss = 1.3860 | Train Acc = 0.5022 | Val Acc = 0.4867\n",
      "Epoch 300: Loss = 1.3847 | Train Acc = 0.5022 | Val Acc = 0.4867\n",
      "Epoch 400: Loss = 1.3114 | Train Acc = 0.9289 | Val Acc = 0.5000\n",
      "Epoch 500: Loss = 0.0244 | Train Acc = 1.0000 | Val Acc = 0.5133\n",
      "Epoch 600: Loss = 0.0084 | Train Acc = 1.0000 | Val Acc = 0.5067\n",
      "Epoch 700: Loss = 0.0050 | Train Acc = 1.0000 | Val Acc = 0.5200\n",
      "Epoch 800: Loss = 0.0036 | Train Acc = 1.0000 | Val Acc = 0.5067\n",
      "Epoch 900: Loss = 0.0028 | Train Acc = 1.0000 | Val Acc = 0.5000\n",
      "Epoch 999: Loss = 0.0024 | Train Acc = 1.0000 | Val Acc = 0.5000\n",
      "Final Test Accuracy: 0.5200\n",
      "FACES Test Accuracy with 225 samples: 0.5200\n",
      "\n",
      " FACES: Training on 270 samples (60%)\n",
      "Epoch 0: Loss = 1.3863 | Train Acc = 0.5111 | Val Acc = 0.4867\n",
      "Epoch 100: Loss = 1.3857 | Train Acc = 0.5111 | Val Acc = 0.4867\n",
      "Epoch 200: Loss = 1.3856 | Train Acc = 0.5111 | Val Acc = 0.4867\n",
      "Epoch 300: Loss = 1.3851 | Train Acc = 0.5111 | Val Acc = 0.4867\n",
      "Epoch 400: Loss = 1.3786 | Train Acc = 0.5111 | Val Acc = 0.4867\n",
      "Epoch 500: Loss = 0.1865 | Train Acc = 1.0000 | Val Acc = 0.5133\n",
      "Epoch 600: Loss = 0.0127 | Train Acc = 1.0000 | Val Acc = 0.5133\n",
      "Epoch 700: Loss = 0.0061 | Train Acc = 1.0000 | Val Acc = 0.5133\n",
      "Epoch 800: Loss = 0.0040 | Train Acc = 1.0000 | Val Acc = 0.5133\n",
      "Epoch 900: Loss = 0.0030 | Train Acc = 1.0000 | Val Acc = 0.5133\n",
      "Epoch 999: Loss = 0.0025 | Train Acc = 1.0000 | Val Acc = 0.5200\n",
      "Final Test Accuracy: 0.5200\n",
      "FACES Test Accuracy with 270 samples: 0.5200\n",
      "\n",
      " FACES: Training on 315 samples (70%)\n",
      "Epoch 0: Loss = 1.3863 | Train Acc = 0.5016 | Val Acc = 0.5333\n",
      "Epoch 100: Loss = 1.3862 | Train Acc = 0.5048 | Val Acc = 0.5133\n",
      "Epoch 200: Loss = 1.3861 | Train Acc = 0.5048 | Val Acc = 0.5133\n",
      "Epoch 300: Loss = 1.3859 | Train Acc = 0.5048 | Val Acc = 0.5133\n",
      "Epoch 400: Loss = 1.3850 | Train Acc = 0.5048 | Val Acc = 0.5133\n",
      "Epoch 500: Loss = 1.3698 | Train Acc = 0.8000 | Val Acc = 0.5400\n",
      "Epoch 600: Loss = 0.0655 | Train Acc = 1.0000 | Val Acc = 0.4533\n",
      "Epoch 700: Loss = 0.0108 | Train Acc = 1.0000 | Val Acc = 0.4600\n",
      "Epoch 800: Loss = 0.0057 | Train Acc = 1.0000 | Val Acc = 0.4600\n",
      "Epoch 900: Loss = 0.0038 | Train Acc = 1.0000 | Val Acc = 0.4600\n",
      "Epoch 999: Loss = 0.0029 | Train Acc = 1.0000 | Val Acc = 0.4667\n",
      "Final Test Accuracy: 0.5400\n",
      "FACES Test Accuracy with 315 samples: 0.5400\n",
      "\n",
      " FACES: Training on 360 samples (80%)\n",
      "Epoch 0: Loss = 1.3863 | Train Acc = 0.5222 | Val Acc = 0.5133\n",
      "Epoch 100: Loss = 1.3843 | Train Acc = 0.5222 | Val Acc = 0.5133\n",
      "Epoch 200: Loss = 1.3842 | Train Acc = 0.5222 | Val Acc = 0.5133\n",
      "Epoch 300: Loss = 1.3841 | Train Acc = 0.5222 | Val Acc = 0.5133\n",
      "Epoch 400: Loss = 1.3834 | Train Acc = 0.5222 | Val Acc = 0.5133\n",
      "Epoch 500: Loss = 1.3768 | Train Acc = 0.5222 | Val Acc = 0.5133\n",
      "Epoch 600: Loss = 0.5146 | Train Acc = 0.9583 | Val Acc = 0.4800\n",
      "Epoch 700: Loss = 0.0146 | Train Acc = 1.0000 | Val Acc = 0.4600\n",
      "Epoch 800: Loss = 0.0065 | Train Acc = 1.0000 | Val Acc = 0.4533\n",
      "Epoch 900: Loss = 0.0041 | Train Acc = 1.0000 | Val Acc = 0.4467\n",
      "Epoch 999: Loss = 0.0030 | Train Acc = 1.0000 | Val Acc = 0.4533\n",
      "Early stopping triggered.\n",
      "Final Test Accuracy: 0.5133\n",
      "FACES Test Accuracy with 360 samples: 0.5133\n",
      "\n",
      " FACES: Training on 405 samples (90%)\n",
      "Epoch 0: Loss = 1.3863 | Train Acc = 0.5111 | Val Acc = 0.5133\n",
      "Epoch 100: Loss = 1.3858 | Train Acc = 0.5111 | Val Acc = 0.5133\n",
      "Epoch 200: Loss = 1.3857 | Train Acc = 0.5111 | Val Acc = 0.5133\n",
      "Epoch 300: Loss = 1.3856 | Train Acc = 0.5111 | Val Acc = 0.5133\n",
      "Epoch 400: Loss = 1.3852 | Train Acc = 0.5111 | Val Acc = 0.5133\n",
      "Epoch 500: Loss = 1.3826 | Train Acc = 0.5111 | Val Acc = 0.5133\n",
      "Epoch 600: Loss = 1.2347 | Train Acc = 0.9407 | Val Acc = 0.4933\n",
      "Epoch 700: Loss = 0.0306 | Train Acc = 1.0000 | Val Acc = 0.4800\n",
      "Epoch 800: Loss = 0.0092 | Train Acc = 1.0000 | Val Acc = 0.4933\n",
      "Epoch 900: Loss = 0.0052 | Train Acc = 1.0000 | Val Acc = 0.4800\n",
      "Epoch 999: Loss = 0.0036 | Train Acc = 1.0000 | Val Acc = 0.4800\n",
      "Early stopping triggered.\n",
      "Final Test Accuracy: 0.5133\n",
      "FACES Test Accuracy with 405 samples: 0.5133\n",
      "\n",
      " FACES: Training on 451 samples (100%)\n",
      "Epoch 0: Loss = 1.3863 | Train Acc = 0.5188 | Val Acc = 0.5133\n",
      "Epoch 100: Loss = 1.3848 | Train Acc = 0.5188 | Val Acc = 0.5133\n",
      "Epoch 200: Loss = 1.3848 | Train Acc = 0.5188 | Val Acc = 0.5133\n",
      "Epoch 300: Loss = 1.3847 | Train Acc = 0.5188 | Val Acc = 0.5133\n",
      "Epoch 400: Loss = 1.3843 | Train Acc = 0.5188 | Val Acc = 0.5133\n",
      "Epoch 500: Loss = 1.3821 | Train Acc = 0.5188 | Val Acc = 0.5133\n",
      "Epoch 600: Loss = 1.2998 | Train Acc = 0.9069 | Val Acc = 0.5067\n",
      "Epoch 700: Loss = 0.0412 | Train Acc = 1.0000 | Val Acc = 0.5000\n",
      "Epoch 800: Loss = 0.0103 | Train Acc = 1.0000 | Val Acc = 0.4800\n",
      "Epoch 900: Loss = 0.0056 | Train Acc = 1.0000 | Val Acc = 0.4867\n",
      "Epoch 999: Loss = 0.0038 | Train Acc = 1.0000 | Val Acc = 0.4867\n",
      "Early stopping triggered.\n",
      "Final Test Accuracy: 0.5133\n",
      "FACES Test Accuracy with 451 samples: 0.5133\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing neural net on face data\")\n",
    "\n",
    "X_face_train_raw, y_face_train_raw = load_dataset(face_train_data_file, face_train_label_file, size=NUM_FACE_TRAINING)\n",
    "X_face_test_raw, y_face_test_raw   = load_dataset(face_test_data_file, face_test_label_file, size=NUM_FACE_TESTING)\n",
    "X_face_val_raw, y_face_val_raw   = load_dataset(face_test_data_file, face_test_label_file, size=NUM_FACE_VALIDATION)\n",
    "\n",
    "X_face_train = np.array(X_face_train_raw).T\n",
    "X_face_test = np.array(X_face_test_raw).T\n",
    "X_face_val = np.array(X_face_val_raw).T\n",
    "y_face_train = one_hot_encode(y_face_train_raw, num_classes=2)\n",
    "y_face_test = one_hot_encode(y_face_test_raw, num_classes=2)\n",
    "y_face_val = one_hot_encode(y_face_val_raw, num_classes=2)\n",
    "\n",
    "# Train on increasing percentages of FACE data \n",
    "percentages = [0.1 * i for i in range(1, 11)]  # 10% to 100%\n",
    "total_face_samples = X_face_train.shape[1]\n",
    "\n",
    "face_results = []\n",
    "\n",
    "for pct in percentages:\n",
    "    n = int(pct * total_face_samples)\n",
    "    X_face_subset = X_face_train[:, :n]\n",
    "    y_face_subset = y_face_train[:, :n]\n",
    "\n",
    "    print(f\"\\n FACES: Training on {n} samples ({int(pct * 100)}%)\")\n",
    "\n",
    "    trained_face_params = train_neural_net( # ??? what should this be, still overfitting ???\n",
    "        X_face_subset, y_face_subset,\n",
    "        X_face_test, y_face_test,\n",
    "        input_size=1680, \n",
    "        h1=64, h2=32, output_size=2,\n",
    "        epochs=1000, lr=0.1,\n",
    "        X_val=X_face_val, y_val=y_face_val,\n",
    "        early_stopping=True, patience=10\n",
    "    )\n",
    "\n",
    "    test_preds = predict_nn(X_face_test, trained_face_params)\n",
    "    test_acc = evaluate(test_preds, np.argmax(y_face_test, axis=0))\n",
    "    face_results.append((n, test_acc))\n",
    "    print(f\"FACES Test Accuracy with {n} samples: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5dfbae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
