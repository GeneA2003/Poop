{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GeneA2003/Poop/blob/main/FinalProjectIntrotoAI_Perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkW-A237B_Wl"
      },
      "source": [
        "Data Read Codeblock"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "O8wHWHMtCDYR"
      },
      "outputs": [],
      "source": [
        "from typing import Literal\n",
        "import numpy as np\n",
        "\n",
        "DATASET_INFO = {\n",
        "    \"digit\": {\n",
        "        \"images\": {\n",
        "            \"train\": \"data/digitdata/trainingimages\",\n",
        "            \"validation\": \"data/digitdata/validationimages\",\n",
        "            \"test\": \"data/digitdata/testimages\",\n",
        "        },\n",
        "        \"labels\": {\n",
        "            \"train\": \"data/digitdata/traininglabels\",\n",
        "            \"validation\": \"data/digitdata/validationlabels\",\n",
        "            \"test\": \"data/digitdata/testlabels\",\n",
        "        },\n",
        "        \"width\": 28,\n",
        "        \"height\": 28,\n",
        "    },\n",
        "    \"face\": {\n",
        "        \"images\": {\n",
        "            \"train\": \"data/facedata/facedatatrain\",\n",
        "            \"validation\": \"data/facedata/facedatavalidation\",\n",
        "            \"test\": \"data/facedata/facedatatest\",\n",
        "        },\n",
        "        \"labels\": {\n",
        "            \"train\": \"data/facedata/facedatatrainlabels\",\n",
        "            \"validation\": \"data/facedata/facedatavalidationlabels\",\n",
        "            \"test\": \"data/facedata/facedatatestlabels\",\n",
        "        },\n",
        "        \"width\": 60,\n",
        "        \"height\": 70,\n",
        "    },\n",
        "}\n",
        "\n",
        "\n",
        "def load_data(\n",
        "        dataset: Literal[\"digit\", \"face\"],\n",
        "        split: Literal[\"train\", \"validation\", \"test\"],\n",
        "):\n",
        "    info = DATASET_INFO[dataset]\n",
        "\n",
        "    # imgs\n",
        "    ipath = info[\"images\"][split]\n",
        "    with open(ipath) as f:\n",
        "        ilines = f.readlines()\n",
        "\n",
        "    ibuf = np.zeros(shape=(len(ilines), info[\"width\"]), dtype=np.uint8)\n",
        "\n",
        "    for row, line in enumerate(ilines):\n",
        "        for col, ch in enumerate(line):\n",
        "            if ch == \" \":\n",
        "                pixel = 0\n",
        "            elif ch == \"+\":\n",
        "                pixel = 1\n",
        "            elif ch == \"#\":\n",
        "                pixel = 2\n",
        "            else:\n",
        "                continue\n",
        "            ibuf[row, col] = pixel\n",
        "\n",
        "    ibuf = ibuf.reshape(len(ilines) // info[\"height\"], info[\"height\"], info[\"width\"])\n",
        "\n",
        "    # labels\n",
        "    lpath = info[\"labels\"][split]\n",
        "    with open(lpath) as f:\n",
        "        llines = f.readlines()\n",
        "\n",
        "    lbuf = np.zeros(shape=(len(llines)), dtype=np.uint8)\n",
        "    for i, label in enumerate(llines):\n",
        "        lbuf[i] = int(label)\n",
        "\n",
        "    return ibuf, lbuf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_F_z0KhYA2h"
      },
      "source": [
        "imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "41k25YIl0KeP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "\n",
        "#for charts and graphs\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "import os\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Unzip and Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4pzOoiSUBVmX"
      },
      "outputs": [],
      "source": [
        "# unzip data\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "if not os.path.exists(\"data\"):\n",
        "    with zipfile.ZipFile(\"data.zip\", \"r\") as zip_ref:\n",
        "        zip_ref.extractall(\"data\")\n",
        "        \n",
        "# filepaths\n",
        "train_data_file = \"data/digitdata/trainingimages\"\n",
        "train_label_file = \"data/digitdata/traininglabels\"\n",
        "val_data_file = \"data/digitdata/validationimages\"\n",
        "val_label_file = \"data/digitdata/validationlabels\"\n",
        "test_data_file = \"data/digitdata/testimages\"\n",
        "test_label_file = \"data/digitdata/testlabels\"\n",
        "\n",
        "face_train_data_file = \"data/facedata/facedatatrain\"\n",
        "face_train_label_file = \"data/facedata/facedatatrainlabels\"\n",
        "face_val_data_file   = \"data/facedata/facedatavalidation\"\n",
        "face_val_label_file  = \"data/facedata/facedatavalidationlabels\"\n",
        "face_test_data_file  = \"data/facedata/facedatatest\"\n",
        "face_test_label_file = \"data/facedata/facedatatestlabels\"\n",
        "\n",
        "def read_data_file(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    return [line.rstrip(\"\\n\") for line in lines]\n",
        "\n",
        "def extract_features(raw_data):\n",
        "    features = []\n",
        "    for i in range(0, len(raw_data), 28):\n",
        "        image = raw_data[i:i+28]\n",
        "        feature = [1 if ch != ' ' else 0 for row in image for ch in row]\n",
        "        features.append(feature)\n",
        "    return features\n",
        "\n",
        "\n",
        "def read_labels(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    return [int(line.strip()) for line in lines]\n",
        "\n",
        "def load_dataset(data_file, label_file, size=None):\n",
        "    raw_data = read_data_file(data_file)\n",
        "    raw_labels = read_labels(label_file)\n",
        "\n",
        "    features = extract_features(raw_data)\n",
        "    if size is not None:\n",
        "        combined = list(zip(features, raw_labels))\n",
        "        random.shuffle(combined)\n",
        "        features, raw_labels = zip(*combined[:size])\n",
        "\n",
        "    return list(features), list(raw_labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uO9iv-yx0czj"
      },
      "source": [
        "Hyperparamaeters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "V_mefgZX0evF"
      },
      "outputs": [],
      "source": [
        "DIGIT_UNROLLED_FEATURES = 28 * 28\n",
        "FACE_UNROLLED_FEATURES = 60 * 70\n",
        "NUM_CLASSES = 10\n",
        "LEARNING_RATE = 0.1\n",
        "EPOCHS = 10\n",
        "DATA_POINT_PERC = 10\n",
        "FACE_CLASSES = 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXUYDvIr02UG"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vGz1xVZyAxRy"
      },
      "outputs": [],
      "source": [
        "# Helper Functions\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x, axis=0, keepdims=True))\n",
        "    return e_x / e_x.sum(axis=0, keepdims=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiJbl6FnAzlI"
      },
      "source": [
        "Perception Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tjMEAnShA29u"
      },
      "outputs": [],
      "source": [
        "class Perceptron:\n",
        "\n",
        "    output = []\n",
        "    training_times = []\n",
        "\n",
        "    def run_percep_on_data(self, split, perceptron):\n",
        "\n",
        "\n",
        "\n",
        "        self.train_func = {\n",
        "\n",
        "            'face': self.trainFace,\n",
        "\n",
        "            'digit': self.trainDigit,\n",
        "\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "        if perceptron == 'face':\n",
        "\n",
        "            classes = FACE_CLASSES\n",
        "\n",
        "            features = FACE_UNROLLED_FEATURES\n",
        "\n",
        "\n",
        "\n",
        "        elif perceptron == 'digit':\n",
        "\n",
        "            classes = NUM_CLASSES\n",
        "\n",
        "            features = DIGIT_UNROLLED_FEATURES\n",
        "\n",
        "        else:\n",
        "\n",
        "            return 'invalid input'\n",
        "\n",
        "\n",
        "\n",
        "        images, labels = load_data(perceptron, split)\n",
        "\n",
        "        images = images.reshape(images.shape[0], -1)  # Flatten 2D images into 1D feature vectors\n",
        "\n",
        "        print(f'digit, {split}')\n",
        "\n",
        "\n",
        "\n",
        "        #while loop allows for the data to be tested independently on increasing percents of data\n",
        "\n",
        "        percent_of_data = 0.1\n",
        "\n",
        "        while percent_of_data <= 1:\n",
        "\n",
        "                print(f'Running {perceptron} on perc_of_data= {percent_of_data}' )\n",
        "                \n",
        "                start_time = time.time()\n",
        "\n",
        "                self.bias = np.zeros(classes)\n",
        "\n",
        "                self.weights = np.random.randn(features, classes) * 0.01\n",
        "\n",
        "                self.train_func[perceptron](images,labels, percent_of_data)\n",
        "                \n",
        "                end_time = time.time() \n",
        "                training_time = end_time - start_time  \n",
        "                self.training_times.append((percent_of_data, training_time))  \n",
        "\n",
        "                percent_of_data = round(percent_of_data + 0.1, 2)\n",
        "\n",
        "        #print(self.output)\n",
        "\n",
        "        for data_percentage in self.output:\n",
        "\n",
        "           print(f'data perc = {data_percentage[0]}')\n",
        "\n",
        "           for index, epoch_data in enumerate(data_percentage[1]):\n",
        "\n",
        "               print(f' epoch num = {index}')\n",
        "\n",
        "               print(f'training =  {str(epoch_data[0])}, validation = {str(epoch_data[1])}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #Fixed the training by epochs\n",
        "\n",
        "    # images[0] contains the num of images\n",
        "\n",
        "    # pixel is a full image -> this means that it's currently set to view 10 images\n",
        "\n",
        "    def trainDigit(self, images, labels, perc_of_data):\n",
        "\n",
        "        vimages, vlabels = load_data('digit', 'validation')\n",
        "\n",
        "        #added test set\n",
        "\n",
        "        timages, tlabels = load_data('digit', 'train')\n",
        "\n",
        "\n",
        "\n",
        "        #added to ensure that only a percentage of the data set is used\n",
        "\n",
        "        max_image_len = int(images.shape[0] * perc_of_data)\n",
        "\n",
        "        max_image_subset = images[0:max_image_len, :]\n",
        "\n",
        "        epoch_data = []\n",
        "\n",
        "\n",
        "\n",
        "        for j in range(EPOCHS):\n",
        "\n",
        "\n",
        "\n",
        "            #count added to see if correct val\n",
        "\n",
        "            correct_predictions = 0\n",
        "\n",
        "            for row, pixel in enumerate(max_image_subset):\n",
        "\n",
        "                #label is used to classify -> 10 indices for 10 different types of nums (0-9)\n",
        "\n",
        "                label = np.zeros(NUM_CLASSES)\n",
        "\n",
        "\n",
        "\n",
        "                #the label index that is the right value is marked 1\n",
        "\n",
        "                label[labels[row]] = 1  # One-hot encoding\n",
        "\n",
        "\n",
        "\n",
        "                #lin-outpout multiplies vertex pixel (1,784) by matrix weights of (784, 10)\n",
        "\n",
        "                lin_output = np.dot(pixel, self.weights) + self.bias\n",
        "\n",
        "\n",
        "\n",
        "                #softmax returns array of probability that digit matches each classification (0-9)\n",
        "\n",
        "                prediction = softmax(lin_output)\n",
        "\n",
        "\n",
        "\n",
        "                #gets the index/classification that has the highest prob\n",
        "\n",
        "                predictedVal = np.argmax(prediction)\n",
        "\n",
        "\n",
        "\n",
        "                if(labels[row] == predictedVal):\n",
        "\n",
        "                    correct_predictions += 1\n",
        "\n",
        "\n",
        "\n",
        "                error = label - prediction\n",
        "\n",
        "\n",
        "\n",
        "                # Update weights and biases using the outer product\n",
        "\n",
        "                self.weights += LEARNING_RATE * np.outer(error, pixel).T\n",
        "\n",
        "                self.bias += LEARNING_RATE * error\n",
        "\n",
        "\n",
        "\n",
        "            print('------')\n",
        "\n",
        "            print(f' End of training on epoch {j}, perc_of_data = {perc_of_data}')\n",
        "\n",
        "            print(f'# of correct predictions {correct_predictions}')\n",
        "\n",
        "            print(f'digit training accur = {correct_predictions/max_image_len}')\n",
        "\n",
        "            print('------')\n",
        "\n",
        "            #check this\n",
        "\n",
        "            validation_res = self.validate_digit(vimages, vlabels, j, self.weights, self.bias)\n",
        "\n",
        "            epoch_data.insert(j,(correct_predictions/max_image_len, validation_res))\n",
        "\n",
        "            correct_predictions = 0\n",
        "\n",
        "        self.output.append((perc_of_data, epoch_data))\n",
        "\n",
        "        self.test_digit(timages, tlabels, j, self.weights, self.bias)\n",
        "\n",
        "\n",
        "\n",
        "    #classes changed to 0,1 ->ie face and not face using a num enum\n",
        "\n",
        "    #tech don't need softmax bc lin_output can give a 0 or 1\n",
        "\n",
        "    #can try to figure that out later\n",
        "\n",
        "\n",
        "\n",
        "    def trainFace(self, images, labels, perc_of_data):\n",
        "\n",
        "        vimages, vlabels = load_data('face', 'validation')\n",
        "\n",
        "        #added test set\n",
        "\n",
        "        timages, tlabels = load_data('face', 'train')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        #max_image_len = 45 & subset is (45, 4200)\n",
        "\n",
        "        max_image_len = int(images.shape[0] * perc_of_data)\n",
        "\n",
        "        max_image_subset = images[0:max_image_len, :]\n",
        "\n",
        "\n",
        "\n",
        "        for j in range(EPOCHS):\n",
        "\n",
        "            correct_predictions = 0\n",
        "\n",
        "            for row, pixel in enumerate(max_image_subset):\n",
        "\n",
        "                label = np.zeros(FACE_CLASSES)\n",
        "\n",
        "                label[labels[row]] = 1  # One-hot encoding\n",
        "\n",
        "\n",
        "\n",
        "                lin_output = np.dot(pixel, self.weights) + self.bias\n",
        "\n",
        "\n",
        "\n",
        "                prediction = softmax(lin_output)\n",
        "\n",
        "\n",
        "\n",
        "                error = label - prediction\n",
        "\n",
        "\n",
        "\n",
        "                predictedVal = np.argmax(prediction)\n",
        "\n",
        "                if(labels[row] == predictedVal):\n",
        "\n",
        "                    correct_predictions += 1\n",
        "\n",
        "\n",
        "\n",
        "                # Update weights and biases using the outer product\n",
        "\n",
        "                self.weights += LEARNING_RATE * np.outer(error, pixel).T\n",
        "\n",
        "                self.bias += LEARNING_RATE * error\n",
        "\n",
        "\n",
        "\n",
        "            print('------')\n",
        "\n",
        "            print(f'End of FACE training on epoch {j}, perc_of_data = {perc_of_data}')\n",
        "\n",
        "            print(f'# of correct predictions = {correct_predictions}')\n",
        "\n",
        "            print(f'Face training accur = {correct_predictions/max_image_len}')\n",
        "\n",
        "            print('------')\n",
        "\n",
        "            correct_predictions = 0\n",
        "\n",
        "            self.validate_face(vimages, vlabels, j, self.weights, self.bias)\n",
        "\n",
        "        self.test_face(timages, tlabels, j, self.weights, self.bias)\n",
        "\n",
        "\n",
        "\n",
        "    #doesn't affect weights -> just used to see how well the model is doing against\n",
        "\n",
        "    #unseen examples\n",
        "\n",
        "    def validate_digit(self, images, labels, i, weights, bias) -> float:\n",
        "\n",
        "\n",
        "\n",
        "        #images start as (1000, 28,28) -> (1000, 784) after reshape\n",
        "\n",
        "        images = images.reshape(images.shape[0], -1)\n",
        "\n",
        "        correct_predictions = 0\n",
        "\n",
        "\n",
        "\n",
        "        #use entire validation set each epoch -> gives more reliable indicator of performance\n",
        "\n",
        "        for row, pixel in enumerate(images):\n",
        "\n",
        "            label = np.zeros(NUM_CLASSES)\n",
        "\n",
        "            label[labels[row]] = 1  # One-hot encoding\n",
        "\n",
        "            lin_output = np.dot(pixel, self.weights) + self.bias\n",
        "\n",
        "            prediction = softmax(lin_output)\n",
        "\n",
        "\n",
        "\n",
        "            if np.argmax(prediction) == labels[row]:\n",
        "\n",
        "                correct_predictions += 1\n",
        "\n",
        "        print(f'Digit Validation accur = {correct_predictions} / {images.shape[0]}, perc_accur = {correct_predictions / images.shape[0]}')\n",
        "\n",
        "        return correct_predictions / images.shape[0]\n",
        "\n",
        "\n",
        "\n",
        "    def validate_face(self, images, labels, i, weights, bias):\n",
        "\n",
        "            images = images.reshape(images.shape[0], -1)\n",
        "\n",
        "            correct_predictions = 0\n",
        "\n",
        "\n",
        "\n",
        "            for row, pixel in enumerate(images):\n",
        "\n",
        "                label = np.zeros(FACE_CLASSES)\n",
        "\n",
        "                label[labels[row]] = 1  # One-hot encoding\n",
        "\n",
        "                lin_output = np.dot(pixel, self.weights) + self.bias\n",
        "\n",
        "                prediction = softmax(lin_output)\n",
        "\n",
        "\n",
        "\n",
        "                if np.argmax(prediction) == labels[row]:\n",
        "\n",
        "                    correct_predictions += 1\n",
        "\n",
        "            print(f'Face Validation accur = {correct_predictions} / {images.shape[0]}, perc_accur = {correct_predictions / images.shape[0]}')\n",
        "\n",
        "\n",
        "\n",
        "    def test_face(self, images, labels, i, weights, bias):\n",
        "\n",
        "        #copied from validateface\n",
        "\n",
        "        images = images.reshape(images.shape[0], -1)\n",
        "\n",
        "        correct_predictions = 0\n",
        "\n",
        "\n",
        "\n",
        "        for row, pixel in enumerate(images):\n",
        "\n",
        "            label = np.zeros(FACE_CLASSES)\n",
        "\n",
        "            label[labels[row]] = 1  # One-hot encoding\n",
        "\n",
        "            lin_output = np.dot(pixel, self.weights) + self.bias\n",
        "\n",
        "            prediction = softmax(lin_output)\n",
        "\n",
        "\n",
        "\n",
        "            if np.argmax(prediction) == labels[row]:\n",
        "\n",
        "                correct_predictions += 1\n",
        "\n",
        "        print(f'Face Test accur = {correct_predictions} / {images.shape[0]}, perc_accur = {correct_predictions / images.shape[0]}')\n",
        "\n",
        "\n",
        "\n",
        "    def test_digit(self, images, labels, i, weights, bias):\n",
        "\n",
        "        #copied validate digit\n",
        "\n",
        "        #images start as (1000, 28,28) -> (1000, 784) after reshape\n",
        "\n",
        "        images = images.reshape(images.shape[0], -1)\n",
        "\n",
        "        correct_predictions = 0\n",
        "\n",
        "\n",
        "\n",
        "        #use entire validation set each epoch -> gives more reliable indicator of performance\n",
        "\n",
        "        for row, pixel in enumerate(images):\n",
        "\n",
        "            label = np.zeros(NUM_CLASSES)\n",
        "\n",
        "            label[labels[row]] = 1  # One-hot encoding\n",
        "\n",
        "            lin_output = np.dot(pixel, self.weights) + self.bias\n",
        "\n",
        "            prediction = softmax(lin_output)\n",
        "\n",
        "\n",
        "\n",
        "            if np.argmax(prediction) == labels[row]:\n",
        "\n",
        "                correct_predictions += 1\n",
        "\n",
        "        print(f'Digit Test accur = {correct_predictions} / {images.shape[0]}, perc_accur = {correct_predictions / images.shape[0]}')\n",
        "\n",
        "        return correct_predictions / images.shape[0]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPQcW3rIOjbe"
      },
      "source": [
        "Sample Digit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "iQ9F_VzEOld3",
        "outputId": "39eafab5-5b7a-4c4d-aaeb-fe381dba65bf"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "imgs, labels = load_data(\"digit\", \"train\")\n",
        "\n",
        "# Pick random image\n",
        "idx = random.randint(0, len(imgs) - 1)\n",
        "img = imgs[idx].reshape(28, 28)\n",
        "\n",
        "# Display image\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.title(\"Digit Label: \" + str(labels[idx]))\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "-_IRMhJRP618",
        "outputId": "c43f8205-6bde-4c2e-c97f-f00ddd428f20"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "imgs, labels = load_data(\"face\", \"train\")\n",
        "\n",
        "idx = random.randint(0, len(imgs) - 1)\n",
        "\n",
        "# Reshape and display\n",
        "img = imgs[idx].reshape(70, 60)\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.title(\"Face Label: \" + str(labels[idx]))\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def export_perceptron_results(perceptron_output, training_times, output_dir='Charts and Graphs'):\n",
        "    # Create output directory if it doesn't exist\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "    else:\n",
        "        # Remove old PDF files\n",
        "        for file in os.listdir(output_dir):\n",
        "            if file.endswith('.pdf') and file.startswith('partA_'):\n",
        "                os.remove(os.path.join(output_dir, file))\n",
        "\n",
        "    # Process results into DataFrame\n",
        "    results = []\n",
        "    for data_percentage, epoch_data in perceptron_output:\n",
        "        for epoch_num, (train_acc, val_acc) in enumerate(epoch_data):\n",
        "            results.append({\n",
        "                'Data %': data_percentage * 100,\n",
        "                'Epoch': epoch_num + 1,\n",
        "                'Training Accuracy': train_acc,\n",
        "                'Validation Accuracy': val_acc\n",
        "            })\n",
        "    \n",
        "    df = pd.DataFrame(results)\n",
        "    \n",
        "    # Add training times to DataFrame\n",
        "    times_df = pd.DataFrame(training_times, columns=['Data %', 'Training Time'])\n",
        "    times_df['Data %'] *= 100  # Convert to percentage\n",
        "    df = df.merge(times_df, on='Data %')\n",
        "\n",
        "    # Export tables\n",
        "    with PdfPages(f'{output_dir}/partA_classification_tables.pdf') as pdf:\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.suptitle('Perceptron Results - Part A', fontsize=14, y=1.05)\n",
        "        plt.axis('tight')\n",
        "        plt.axis('off')\n",
        "        \n",
        "        summary = df.groupby('Data %')[['Training Accuracy', 'Validation Accuracy', 'Training Time']].mean()\n",
        "        table_data = [[f\"{row_name:.1f}%\"] + [f\"{val:.4f}\" for val in row] \n",
        "                     for row_name, row in zip(summary.index, summary.values)]\n",
        "        \n",
        "        table = plt.table(\n",
        "            cellText=table_data,\n",
        "            colLabels=['Data %', 'Avg Training Acc', 'Avg Validation Acc', 'Avg Time (s)'],\n",
        "            loc='center',\n",
        "            cellLoc='center'\n",
        "        )\n",
        "        table.auto_set_font_size(False)\n",
        "        table.set_fontsize(9)\n",
        "        table.scale(1.2, 1.5)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        pdf.savefig(bbox_inches='tight', pad_inches=0.5)\n",
        "        plt.close()\n",
        "\n",
        "    # Export learning curves\n",
        "    with PdfPages(f'{output_dir}/partA_learning_curves.pdf') as pdf:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(df['Data %'].unique(), \n",
        "                df.groupby('Data %')['Training Accuracy'].mean(), \n",
        "                'b.-', label='Training', linewidth=2, markersize=8)\n",
        "        plt.plot(df['Data %'].unique(), \n",
        "                df.groupby('Data %')['Validation Accuracy'].mean(), \n",
        "                'r.-', label='Validation', linewidth=2, markersize=8)\n",
        "        plt.xlabel('Percentage of Training Data', fontsize=12)\n",
        "        plt.ylabel('Accuracy', fontsize=12)\n",
        "        plt.title('Perceptron Learning Curves - Part A', fontsize=14)\n",
        "        plt.grid(True, linestyle='--', alpha=0.7)\n",
        "        plt.legend(fontsize=10)\n",
        "        plt.tight_layout()\n",
        "        pdf.savefig(bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    # Export training times\n",
        "    with PdfPages(f'{output_dir}/partA_training_times.pdf') as pdf:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(df['Data %'].unique(), \n",
        "                df.groupby('Data %')['Training Time'].mean(), \n",
        "                'g.-', linewidth=2, markersize=8)\n",
        "        plt.xlabel('Percentage of Training Data', fontsize=12)\n",
        "        plt.ylabel('Training Time (seconds)', fontsize=12)\n",
        "        plt.title('Perceptron Training Times - Part A', fontsize=14)\n",
        "        plt.grid(True, linestyle='--', alpha=0.7)\n",
        "        plt.tight_layout()\n",
        "        pdf.savefig(bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    # Print summary\n",
        "    print(f\"\\nPart A Results exported to {output_dir}/\")\n",
        "    print(\"\\nPerceptron Classification Summary:\")\n",
        "    print(summary.round(4).to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxk1h9mUON4m"
      },
      "source": [
        "Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymkJEIeSOoNg",
        "outputId": "184c175d-3379-46b4-8594-710cbaf270f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "digit, train\n",
            "Running digit on perc_of_data= 0.1\n",
            "------\n",
            " End of training on epoch 0, perc_of_data = 0.1\n",
            "# of correct predictions 333\n",
            "digit training accur = 0.666\n",
            "------\n",
            "Digit Validation accur = 641 / 1000, perc_accur = 0.641\n",
            "------\n",
            " End of training on epoch 1, perc_of_data = 0.1\n",
            "# of correct predictions 406\n",
            "digit training accur = 0.812\n",
            "------\n",
            "Digit Validation accur = 719 / 1000, perc_accur = 0.719\n",
            "------\n",
            " End of training on epoch 2, perc_of_data = 0.1\n",
            "# of correct predictions 443\n",
            "digit training accur = 0.886\n",
            "------\n",
            "Digit Validation accur = 760 / 1000, perc_accur = 0.76\n",
            "------\n",
            " End of training on epoch 3, perc_of_data = 0.1\n",
            "# of correct predictions 470\n",
            "digit training accur = 0.94\n",
            "------\n",
            "Digit Validation accur = 777 / 1000, perc_accur = 0.777\n",
            "------\n",
            " End of training on epoch 4, perc_of_data = 0.1\n",
            "# of correct predictions 475\n",
            "digit training accur = 0.95\n",
            "------\n",
            "Digit Validation accur = 752 / 1000, perc_accur = 0.752\n",
            "------\n",
            " End of training on epoch 5, perc_of_data = 0.1\n",
            "# of correct predictions 482\n",
            "digit training accur = 0.964\n",
            "------\n",
            "Digit Validation accur = 741 / 1000, perc_accur = 0.741\n",
            "------\n",
            " End of training on epoch 6, perc_of_data = 0.1\n",
            "# of correct predictions 483\n",
            "digit training accur = 0.966\n",
            "------\n",
            "Digit Validation accur = 787 / 1000, perc_accur = 0.787\n",
            "------\n",
            " End of training on epoch 7, perc_of_data = 0.1\n",
            "# of correct predictions 494\n",
            "digit training accur = 0.988\n",
            "------\n",
            "Digit Validation accur = 786 / 1000, perc_accur = 0.786\n",
            "------\n",
            " End of training on epoch 8, perc_of_data = 0.1\n",
            "# of correct predictions 488\n",
            "digit training accur = 0.976\n",
            "------\n",
            "Digit Validation accur = 787 / 1000, perc_accur = 0.787\n",
            "------\n",
            " End of training on epoch 9, perc_of_data = 0.1\n",
            "# of correct predictions 496\n",
            "digit training accur = 0.992\n",
            "------\n",
            "Digit Validation accur = 815 / 1000, perc_accur = 0.815\n",
            "Digit Test accur = 4122 / 5000, perc_accur = 0.8244\n",
            "Running digit on perc_of_data= 0.2\n",
            "------\n",
            " End of training on epoch 0, perc_of_data = 0.2\n",
            "# of correct predictions 673\n",
            "digit training accur = 0.673\n",
            "------\n",
            "Digit Validation accur = 751 / 1000, perc_accur = 0.751\n",
            "------\n",
            " End of training on epoch 1, perc_of_data = 0.2\n",
            "# of correct predictions 823\n",
            "digit training accur = 0.823\n",
            "------\n",
            "Digit Validation accur = 710 / 1000, perc_accur = 0.71\n",
            "------\n",
            " End of training on epoch 2, perc_of_data = 0.2\n",
            "# of correct predictions 862\n",
            "digit training accur = 0.862\n",
            "------\n",
            "Digit Validation accur = 728 / 1000, perc_accur = 0.728\n",
            "------\n",
            " End of training on epoch 3, perc_of_data = 0.2\n",
            "# of correct predictions 881\n",
            "digit training accur = 0.881\n",
            "------\n",
            "Digit Validation accur = 778 / 1000, perc_accur = 0.778\n",
            "------\n",
            " End of training on epoch 4, perc_of_data = 0.2\n",
            "# of correct predictions 906\n",
            "digit training accur = 0.906\n",
            "------\n",
            "Digit Validation accur = 691 / 1000, perc_accur = 0.691\n",
            "------\n",
            " End of training on epoch 5, perc_of_data = 0.2\n",
            "# of correct predictions 923\n",
            "digit training accur = 0.923\n",
            "------\n",
            "Digit Validation accur = 775 / 1000, perc_accur = 0.775\n",
            "------\n",
            " End of training on epoch 6, perc_of_data = 0.2\n",
            "# of correct predictions 938\n",
            "digit training accur = 0.938\n",
            "------\n",
            "Digit Validation accur = 774 / 1000, perc_accur = 0.774\n",
            "------\n",
            " End of training on epoch 7, perc_of_data = 0.2\n",
            "# of correct predictions 962\n",
            "digit training accur = 0.962\n",
            "------\n",
            "Digit Validation accur = 759 / 1000, perc_accur = 0.759\n",
            "------\n",
            " End of training on epoch 8, perc_of_data = 0.2\n",
            "# of correct predictions 955\n",
            "digit training accur = 0.955\n",
            "------\n",
            "Digit Validation accur = 780 / 1000, perc_accur = 0.78\n",
            "------\n",
            " End of training on epoch 9, perc_of_data = 0.2\n",
            "# of correct predictions 959\n",
            "digit training accur = 0.959\n",
            "------\n",
            "Digit Validation accur = 782 / 1000, perc_accur = 0.782\n",
            "Digit Test accur = 4250 / 5000, perc_accur = 0.85\n",
            "Running digit on perc_of_data= 0.3\n",
            "------\n",
            " End of training on epoch 0, perc_of_data = 0.3\n",
            "# of correct predictions 1043\n",
            "digit training accur = 0.6953333333333334\n",
            "------\n",
            "Digit Validation accur = 695 / 1000, perc_accur = 0.695\n",
            "------\n",
            " End of training on epoch 1, perc_of_data = 0.3\n",
            "# of correct predictions 1229\n",
            "digit training accur = 0.8193333333333334\n",
            "------\n",
            "Digit Validation accur = 715 / 1000, perc_accur = 0.715\n",
            "------\n",
            " End of training on epoch 2, perc_of_data = 0.3\n",
            "# of correct predictions 1281\n",
            "digit training accur = 0.854\n",
            "------\n",
            "Digit Validation accur = 806 / 1000, perc_accur = 0.806\n",
            "------\n",
            " End of training on epoch 3, perc_of_data = 0.3\n",
            "# of correct predictions 1314\n",
            "digit training accur = 0.876\n",
            "------\n",
            "Digit Validation accur = 806 / 1000, perc_accur = 0.806\n",
            "------\n",
            " End of training on epoch 4, perc_of_data = 0.3\n",
            "# of correct predictions 1336\n",
            "digit training accur = 0.8906666666666667\n",
            "------\n",
            "Digit Validation accur = 799 / 1000, perc_accur = 0.799\n",
            "------\n",
            " End of training on epoch 5, perc_of_data = 0.3\n",
            "# of correct predictions 1358\n",
            "digit training accur = 0.9053333333333333\n",
            "------\n",
            "Digit Validation accur = 792 / 1000, perc_accur = 0.792\n",
            "------\n",
            " End of training on epoch 6, perc_of_data = 0.3\n",
            "# of correct predictions 1390\n",
            "digit training accur = 0.9266666666666666\n",
            "------\n",
            "Digit Validation accur = 821 / 1000, perc_accur = 0.821\n",
            "------\n",
            " End of training on epoch 7, perc_of_data = 0.3\n",
            "# of correct predictions 1406\n",
            "digit training accur = 0.9373333333333334\n",
            "------\n",
            "Digit Validation accur = 815 / 1000, perc_accur = 0.815\n",
            "------\n",
            " End of training on epoch 8, perc_of_data = 0.3\n",
            "# of correct predictions 1411\n",
            "digit training accur = 0.9406666666666667\n",
            "------\n",
            "Digit Validation accur = 795 / 1000, perc_accur = 0.795\n",
            "------\n",
            " End of training on epoch 9, perc_of_data = 0.3\n",
            "# of correct predictions 1426\n",
            "digit training accur = 0.9506666666666667\n",
            "------\n",
            "Digit Validation accur = 810 / 1000, perc_accur = 0.81\n",
            "Digit Test accur = 4341 / 5000, perc_accur = 0.8682\n",
            "Running digit on perc_of_data= 0.4\n",
            "------\n",
            " End of training on epoch 0, perc_of_data = 0.4\n",
            "# of correct predictions 1440\n",
            "digit training accur = 0.72\n",
            "------\n",
            "Digit Validation accur = 808 / 1000, perc_accur = 0.808\n",
            "------\n",
            " End of training on epoch 1, perc_of_data = 0.4\n",
            "# of correct predictions 1644\n",
            "digit training accur = 0.822\n",
            "------\n",
            "Digit Validation accur = 807 / 1000, perc_accur = 0.807\n",
            "------\n",
            " End of training on epoch 2, perc_of_data = 0.4\n",
            "# of correct predictions 1714\n",
            "digit training accur = 0.857\n",
            "------\n",
            "Digit Validation accur = 787 / 1000, perc_accur = 0.787\n",
            "------\n",
            " End of training on epoch 3, perc_of_data = 0.4\n",
            "# of correct predictions 1763\n",
            "digit training accur = 0.8815\n",
            "------\n",
            "Digit Validation accur = 778 / 1000, perc_accur = 0.778\n",
            "------\n",
            " End of training on epoch 4, perc_of_data = 0.4\n",
            "# of correct predictions 1782\n",
            "digit training accur = 0.891\n",
            "------\n",
            "Digit Validation accur = 808 / 1000, perc_accur = 0.808\n",
            "------\n",
            " End of training on epoch 5, perc_of_data = 0.4\n",
            "# of correct predictions 1815\n",
            "digit training accur = 0.9075\n",
            "------\n",
            "Digit Validation accur = 811 / 1000, perc_accur = 0.811\n",
            "------\n",
            " End of training on epoch 6, perc_of_data = 0.4\n",
            "# of correct predictions 1826\n",
            "digit training accur = 0.913\n",
            "------\n",
            "Digit Validation accur = 814 / 1000, perc_accur = 0.814\n",
            "------\n",
            " End of training on epoch 7, perc_of_data = 0.4\n",
            "# of correct predictions 1845\n",
            "digit training accur = 0.9225\n",
            "------\n",
            "Digit Validation accur = 839 / 1000, perc_accur = 0.839\n",
            "------\n",
            " End of training on epoch 8, perc_of_data = 0.4\n",
            "# of correct predictions 1862\n",
            "digit training accur = 0.931\n",
            "------\n",
            "Digit Validation accur = 799 / 1000, perc_accur = 0.799\n",
            "------\n",
            " End of training on epoch 9, perc_of_data = 0.4\n",
            "# of correct predictions 1869\n",
            "digit training accur = 0.9345\n",
            "------\n",
            "Digit Validation accur = 816 / 1000, perc_accur = 0.816\n",
            "Digit Test accur = 4453 / 5000, perc_accur = 0.8906\n",
            "Running digit on perc_of_data= 0.5\n",
            "------\n",
            " End of training on epoch 0, perc_of_data = 0.5\n",
            "# of correct predictions 1861\n",
            "digit training accur = 0.7444\n",
            "------\n",
            "Digit Validation accur = 767 / 1000, perc_accur = 0.767\n",
            "------\n",
            " End of training on epoch 1, perc_of_data = 0.5\n",
            "# of correct predictions 2082\n",
            "digit training accur = 0.8328\n",
            "------\n",
            "Digit Validation accur = 824 / 1000, perc_accur = 0.824\n",
            "------\n",
            " End of training on epoch 2, perc_of_data = 0.5\n",
            "# of correct predictions 2164\n",
            "digit training accur = 0.8656\n",
            "------\n",
            "Digit Validation accur = 794 / 1000, perc_accur = 0.794\n",
            "------\n",
            " End of training on epoch 3, perc_of_data = 0.5\n",
            "# of correct predictions 2219\n",
            "digit training accur = 0.8876\n",
            "------\n",
            "Digit Validation accur = 806 / 1000, perc_accur = 0.806\n",
            "------\n",
            " End of training on epoch 4, perc_of_data = 0.5\n",
            "# of correct predictions 2233\n",
            "digit training accur = 0.8932\n",
            "------\n",
            "Digit Validation accur = 843 / 1000, perc_accur = 0.843\n",
            "------\n",
            " End of training on epoch 5, perc_of_data = 0.5\n",
            "# of correct predictions 2265\n",
            "digit training accur = 0.906\n",
            "------\n",
            "Digit Validation accur = 839 / 1000, perc_accur = 0.839\n",
            "------\n",
            " End of training on epoch 6, perc_of_data = 0.5\n",
            "# of correct predictions 2303\n",
            "digit training accur = 0.9212\n",
            "------\n",
            "Digit Validation accur = 820 / 1000, perc_accur = 0.82\n",
            "------\n",
            " End of training on epoch 7, perc_of_data = 0.5\n",
            "# of correct predictions 2311\n",
            "digit training accur = 0.9244\n",
            "------\n",
            "Digit Validation accur = 821 / 1000, perc_accur = 0.821\n",
            "------\n",
            " End of training on epoch 8, perc_of_data = 0.5\n",
            "# of correct predictions 2324\n",
            "digit training accur = 0.9296\n",
            "------\n",
            "Digit Validation accur = 824 / 1000, perc_accur = 0.824\n",
            "------\n",
            " End of training on epoch 9, perc_of_data = 0.5\n",
            "# of correct predictions 2317\n",
            "digit training accur = 0.9268\n",
            "------\n",
            "Digit Validation accur = 824 / 1000, perc_accur = 0.824\n",
            "Digit Test accur = 4391 / 5000, perc_accur = 0.8782\n",
            "Running digit on perc_of_data= 0.6\n",
            "------\n",
            " End of training on epoch 0, perc_of_data = 0.6\n",
            "# of correct predictions 2279\n",
            "digit training accur = 0.7596666666666667\n",
            "------\n",
            "Digit Validation accur = 852 / 1000, perc_accur = 0.852\n",
            "------\n",
            " End of training on epoch 1, perc_of_data = 0.6\n",
            "# of correct predictions 2532\n",
            "digit training accur = 0.844\n",
            "------\n",
            "Digit Validation accur = 829 / 1000, perc_accur = 0.829\n",
            "------\n",
            " End of training on epoch 2, perc_of_data = 0.6\n",
            "# of correct predictions 2635\n",
            "digit training accur = 0.8783333333333333\n",
            "------\n",
            "Digit Validation accur = 830 / 1000, perc_accur = 0.83\n",
            "------\n",
            " End of training on epoch 3, perc_of_data = 0.6\n",
            "# of correct predictions 2659\n",
            "digit training accur = 0.8863333333333333\n",
            "------\n",
            "Digit Validation accur = 832 / 1000, perc_accur = 0.832\n",
            "------\n",
            " End of training on epoch 4, perc_of_data = 0.6\n",
            "# of correct predictions 2667\n",
            "digit training accur = 0.889\n",
            "------\n",
            "Digit Validation accur = 845 / 1000, perc_accur = 0.845\n",
            "------\n",
            " End of training on epoch 5, perc_of_data = 0.6\n",
            "# of correct predictions 2716\n",
            "digit training accur = 0.9053333333333333\n",
            "------\n",
            "Digit Validation accur = 856 / 1000, perc_accur = 0.856\n",
            "------\n",
            " End of training on epoch 6, perc_of_data = 0.6\n",
            "# of correct predictions 2720\n",
            "digit training accur = 0.9066666666666666\n",
            "------\n",
            "Digit Validation accur = 833 / 1000, perc_accur = 0.833\n",
            "------\n",
            " End of training on epoch 7, perc_of_data = 0.6\n",
            "# of correct predictions 2773\n",
            "digit training accur = 0.9243333333333333\n",
            "------\n",
            "Digit Validation accur = 835 / 1000, perc_accur = 0.835\n",
            "------\n",
            " End of training on epoch 8, perc_of_data = 0.6\n",
            "# of correct predictions 2776\n",
            "digit training accur = 0.9253333333333333\n",
            "------\n",
            "Digit Validation accur = 846 / 1000, perc_accur = 0.846\n",
            "------\n",
            " End of training on epoch 9, perc_of_data = 0.6\n",
            "# of correct predictions 2791\n",
            "digit training accur = 0.9303333333333333\n",
            "------\n",
            "Digit Validation accur = 848 / 1000, perc_accur = 0.848\n",
            "Digit Test accur = 4586 / 5000, perc_accur = 0.9172\n",
            "Running digit on perc_of_data= 0.7\n",
            "------\n",
            " End of training on epoch 0, perc_of_data = 0.7\n",
            "# of correct predictions 2666\n",
            "digit training accur = 0.7617142857142857\n",
            "------\n",
            "Digit Validation accur = 811 / 1000, perc_accur = 0.811\n",
            "------\n",
            " End of training on epoch 1, perc_of_data = 0.7\n",
            "# of correct predictions 2981\n",
            "digit training accur = 0.8517142857142858\n",
            "------\n",
            "Digit Validation accur = 856 / 1000, perc_accur = 0.856\n",
            "------\n",
            " End of training on epoch 2, perc_of_data = 0.7\n",
            "# of correct predictions 3064\n",
            "digit training accur = 0.8754285714285714\n",
            "------\n",
            "Digit Validation accur = 848 / 1000, perc_accur = 0.848\n",
            "------\n",
            " End of training on epoch 3, perc_of_data = 0.7\n",
            "# of correct predictions 3122\n",
            "digit training accur = 0.892\n",
            "------\n",
            "Digit Validation accur = 855 / 1000, perc_accur = 0.855\n",
            "------\n",
            " End of training on epoch 4, perc_of_data = 0.7\n",
            "# of correct predictions 3172\n",
            "digit training accur = 0.9062857142857143\n",
            "------\n",
            "Digit Validation accur = 800 / 1000, perc_accur = 0.8\n",
            "------\n",
            " End of training on epoch 5, perc_of_data = 0.7\n",
            "# of correct predictions 3167\n",
            "digit training accur = 0.9048571428571428\n",
            "------\n",
            "Digit Validation accur = 844 / 1000, perc_accur = 0.844\n",
            "------\n",
            " End of training on epoch 6, perc_of_data = 0.7\n",
            "# of correct predictions 3170\n",
            "digit training accur = 0.9057142857142857\n",
            "------\n",
            "Digit Validation accur = 839 / 1000, perc_accur = 0.839\n",
            "------\n",
            " End of training on epoch 7, perc_of_data = 0.7\n",
            "# of correct predictions 3230\n",
            "digit training accur = 0.9228571428571428\n",
            "------\n",
            "Digit Validation accur = 833 / 1000, perc_accur = 0.833\n",
            "------\n",
            " End of training on epoch 8, perc_of_data = 0.7\n",
            "# of correct predictions 3239\n",
            "digit training accur = 0.9254285714285714\n",
            "------\n",
            "Digit Validation accur = 850 / 1000, perc_accur = 0.85\n",
            "------\n",
            " End of training on epoch 9, perc_of_data = 0.7\n",
            "# of correct predictions 3247\n",
            "digit training accur = 0.9277142857142857\n",
            "------\n",
            "Digit Validation accur = 817 / 1000, perc_accur = 0.817\n",
            "Digit Test accur = 4504 / 5000, perc_accur = 0.9008\n",
            "Running digit on perc_of_data= 0.8\n",
            "------\n",
            " End of training on epoch 0, perc_of_data = 0.8\n",
            "# of correct predictions 3101\n",
            "digit training accur = 0.77525\n",
            "------\n",
            "Digit Validation accur = 820 / 1000, perc_accur = 0.82\n",
            "------\n",
            " End of training on epoch 1, perc_of_data = 0.8\n",
            "# of correct predictions 3384\n",
            "digit training accur = 0.846\n",
            "------\n",
            "Digit Validation accur = 791 / 1000, perc_accur = 0.791\n",
            "------\n",
            " End of training on epoch 2, perc_of_data = 0.8\n",
            "# of correct predictions 3516\n",
            "digit training accur = 0.879\n",
            "------\n",
            "Digit Validation accur = 819 / 1000, perc_accur = 0.819\n",
            "------\n",
            " End of training on epoch 3, perc_of_data = 0.8\n",
            "# of correct predictions 3563\n",
            "digit training accur = 0.89075\n",
            "------\n",
            "Digit Validation accur = 820 / 1000, perc_accur = 0.82\n",
            "------\n",
            " End of training on epoch 4, perc_of_data = 0.8\n",
            "# of correct predictions 3593\n",
            "digit training accur = 0.89825\n",
            "------\n",
            "Digit Validation accur = 798 / 1000, perc_accur = 0.798\n",
            "------\n",
            " End of training on epoch 5, perc_of_data = 0.8\n",
            "# of correct predictions 3607\n",
            "digit training accur = 0.90175\n",
            "------\n",
            "Digit Validation accur = 812 / 1000, perc_accur = 0.812\n",
            "------\n",
            " End of training on epoch 6, perc_of_data = 0.8\n",
            "# of correct predictions 3656\n",
            "digit training accur = 0.914\n",
            "------\n",
            "Digit Validation accur = 835 / 1000, perc_accur = 0.835\n",
            "------\n",
            " End of training on epoch 7, perc_of_data = 0.8\n",
            "# of correct predictions 3659\n",
            "digit training accur = 0.91475\n",
            "------\n",
            "Digit Validation accur = 844 / 1000, perc_accur = 0.844\n",
            "------\n",
            " End of training on epoch 8, perc_of_data = 0.8\n",
            "# of correct predictions 3696\n",
            "digit training accur = 0.924\n",
            "------\n",
            "Digit Validation accur = 849 / 1000, perc_accur = 0.849\n",
            "------\n",
            " End of training on epoch 9, perc_of_data = 0.8\n",
            "# of correct predictions 3734\n",
            "digit training accur = 0.9335\n",
            "------\n",
            "Digit Validation accur = 839 / 1000, perc_accur = 0.839\n",
            "Digit Test accur = 4531 / 5000, perc_accur = 0.9062\n",
            "Running digit on perc_of_data= 0.9\n",
            "------\n",
            " End of training on epoch 0, perc_of_data = 0.9\n",
            "# of correct predictions 3550\n",
            "digit training accur = 0.7888888888888889\n",
            "------\n",
            "Digit Validation accur = 744 / 1000, perc_accur = 0.744\n",
            "------\n",
            " End of training on epoch 1, perc_of_data = 0.9\n",
            "# of correct predictions 3860\n",
            "digit training accur = 0.8577777777777778\n",
            "------\n",
            "Digit Validation accur = 750 / 1000, perc_accur = 0.75\n",
            "------\n",
            " End of training on epoch 2, perc_of_data = 0.9\n",
            "# of correct predictions 3928\n",
            "digit training accur = 0.8728888888888889\n",
            "------\n",
            "Digit Validation accur = 819 / 1000, perc_accur = 0.819\n",
            "------\n",
            " End of training on epoch 3, perc_of_data = 0.9\n",
            "# of correct predictions 4002\n",
            "digit training accur = 0.8893333333333333\n",
            "------\n",
            "Digit Validation accur = 809 / 1000, perc_accur = 0.809\n",
            "------\n",
            " End of training on epoch 4, perc_of_data = 0.9\n",
            "# of correct predictions 4030\n",
            "digit training accur = 0.8955555555555555\n",
            "------\n",
            "Digit Validation accur = 830 / 1000, perc_accur = 0.83\n",
            "------\n",
            " End of training on epoch 5, perc_of_data = 0.9\n",
            "# of correct predictions 4045\n",
            "digit training accur = 0.8988888888888888\n",
            "------\n",
            "Digit Validation accur = 850 / 1000, perc_accur = 0.85\n",
            "------\n",
            " End of training on epoch 6, perc_of_data = 0.9\n",
            "# of correct predictions 4099\n",
            "digit training accur = 0.9108888888888889\n",
            "------\n",
            "Digit Validation accur = 852 / 1000, perc_accur = 0.852\n",
            "------\n",
            " End of training on epoch 7, perc_of_data = 0.9\n",
            "# of correct predictions 4101\n",
            "digit training accur = 0.9113333333333333\n",
            "------\n",
            "Digit Validation accur = 829 / 1000, perc_accur = 0.829\n",
            "------\n",
            " End of training on epoch 8, perc_of_data = 0.9\n",
            "# of correct predictions 4152\n",
            "digit training accur = 0.9226666666666666\n",
            "------\n",
            "Digit Validation accur = 817 / 1000, perc_accur = 0.817\n",
            "------\n",
            " End of training on epoch 9, perc_of_data = 0.9\n",
            "# of correct predictions 4145\n",
            "digit training accur = 0.9211111111111111\n",
            "------\n",
            "Digit Validation accur = 838 / 1000, perc_accur = 0.838\n",
            "Digit Test accur = 4629 / 5000, perc_accur = 0.9258\n",
            "Running digit on perc_of_data= 1.0\n",
            "------\n",
            " End of training on epoch 0, perc_of_data = 1.0\n",
            "# of correct predictions 3960\n",
            "digit training accur = 0.792\n",
            "------\n",
            "Digit Validation accur = 836 / 1000, perc_accur = 0.836\n",
            "------\n",
            " End of training on epoch 1, perc_of_data = 1.0\n",
            "# of correct predictions 4318\n",
            "digit training accur = 0.8636\n",
            "------\n",
            "Digit Validation accur = 817 / 1000, perc_accur = 0.817\n",
            "------\n",
            " End of training on epoch 2, perc_of_data = 1.0\n",
            "# of correct predictions 4371\n",
            "digit training accur = 0.8742\n",
            "------\n",
            "Digit Validation accur = 848 / 1000, perc_accur = 0.848\n",
            "------\n",
            " End of training on epoch 3, perc_of_data = 1.0\n",
            "# of correct predictions 4422\n",
            "digit training accur = 0.8844\n",
            "------\n",
            "Digit Validation accur = 840 / 1000, perc_accur = 0.84\n",
            "------\n",
            " End of training on epoch 4, perc_of_data = 1.0\n",
            "# of correct predictions 4468\n",
            "digit training accur = 0.8936\n",
            "------\n",
            "Digit Validation accur = 834 / 1000, perc_accur = 0.834\n",
            "------\n",
            " End of training on epoch 5, perc_of_data = 1.0\n",
            "# of correct predictions 4558\n",
            "digit training accur = 0.9116\n",
            "------\n",
            "Digit Validation accur = 851 / 1000, perc_accur = 0.851\n",
            "------\n",
            " End of training on epoch 6, perc_of_data = 1.0\n",
            "# of correct predictions 4568\n",
            "digit training accur = 0.9136\n",
            "------\n",
            "Digit Validation accur = 859 / 1000, perc_accur = 0.859\n",
            "------\n",
            " End of training on epoch 7, perc_of_data = 1.0\n",
            "# of correct predictions 4594\n",
            "digit training accur = 0.9188\n",
            "------\n",
            "Digit Validation accur = 822 / 1000, perc_accur = 0.822\n",
            "------\n",
            " End of training on epoch 8, perc_of_data = 1.0\n",
            "# of correct predictions 4572\n",
            "digit training accur = 0.9144\n",
            "------\n",
            "Digit Validation accur = 831 / 1000, perc_accur = 0.831\n",
            "------\n",
            " End of training on epoch 9, perc_of_data = 1.0\n",
            "# of correct predictions 4597\n",
            "digit training accur = 0.9194\n",
            "------\n",
            "Digit Validation accur = 840 / 1000, perc_accur = 0.84\n",
            "Digit Test accur = 4674 / 5000, perc_accur = 0.9348\n",
            "data perc = 0.1\n",
            " epoch num = 0\n",
            "training =  0.666, validation = 0.641\n",
            " epoch num = 1\n",
            "training =  0.812, validation = 0.719\n",
            " epoch num = 2\n",
            "training =  0.886, validation = 0.76\n",
            " epoch num = 3\n",
            "training =  0.94, validation = 0.777\n",
            " epoch num = 4\n",
            "training =  0.95, validation = 0.752\n",
            " epoch num = 5\n",
            "training =  0.964, validation = 0.741\n",
            " epoch num = 6\n",
            "training =  0.966, validation = 0.787\n",
            " epoch num = 7\n",
            "training =  0.988, validation = 0.786\n",
            " epoch num = 8\n",
            "training =  0.976, validation = 0.787\n",
            " epoch num = 9\n",
            "training =  0.992, validation = 0.815\n",
            "data perc = 0.2\n",
            " epoch num = 0\n",
            "training =  0.673, validation = 0.751\n",
            " epoch num = 1\n",
            "training =  0.823, validation = 0.71\n",
            " epoch num = 2\n",
            "training =  0.862, validation = 0.728\n",
            " epoch num = 3\n",
            "training =  0.881, validation = 0.778\n",
            " epoch num = 4\n",
            "training =  0.906, validation = 0.691\n",
            " epoch num = 5\n",
            "training =  0.923, validation = 0.775\n",
            " epoch num = 6\n",
            "training =  0.938, validation = 0.774\n",
            " epoch num = 7\n",
            "training =  0.962, validation = 0.759\n",
            " epoch num = 8\n",
            "training =  0.955, validation = 0.78\n",
            " epoch num = 9\n",
            "training =  0.959, validation = 0.782\n",
            "data perc = 0.3\n",
            " epoch num = 0\n",
            "training =  0.6953333333333334, validation = 0.695\n",
            " epoch num = 1\n",
            "training =  0.8193333333333334, validation = 0.715\n",
            " epoch num = 2\n",
            "training =  0.854, validation = 0.806\n",
            " epoch num = 3\n",
            "training =  0.876, validation = 0.806\n",
            " epoch num = 4\n",
            "training =  0.8906666666666667, validation = 0.799\n",
            " epoch num = 5\n",
            "training =  0.9053333333333333, validation = 0.792\n",
            " epoch num = 6\n",
            "training =  0.9266666666666666, validation = 0.821\n",
            " epoch num = 7\n",
            "training =  0.9373333333333334, validation = 0.815\n",
            " epoch num = 8\n",
            "training =  0.9406666666666667, validation = 0.795\n",
            " epoch num = 9\n",
            "training =  0.9506666666666667, validation = 0.81\n",
            "data perc = 0.4\n",
            " epoch num = 0\n",
            "training =  0.72, validation = 0.808\n",
            " epoch num = 1\n",
            "training =  0.822, validation = 0.807\n",
            " epoch num = 2\n",
            "training =  0.857, validation = 0.787\n",
            " epoch num = 3\n",
            "training =  0.8815, validation = 0.778\n",
            " epoch num = 4\n",
            "training =  0.891, validation = 0.808\n",
            " epoch num = 5\n",
            "training =  0.9075, validation = 0.811\n",
            " epoch num = 6\n",
            "training =  0.913, validation = 0.814\n",
            " epoch num = 7\n",
            "training =  0.9225, validation = 0.839\n",
            " epoch num = 8\n",
            "training =  0.931, validation = 0.799\n",
            " epoch num = 9\n",
            "training =  0.9345, validation = 0.816\n",
            "data perc = 0.5\n",
            " epoch num = 0\n",
            "training =  0.7444, validation = 0.767\n",
            " epoch num = 1\n",
            "training =  0.8328, validation = 0.824\n",
            " epoch num = 2\n",
            "training =  0.8656, validation = 0.794\n",
            " epoch num = 3\n",
            "training =  0.8876, validation = 0.806\n",
            " epoch num = 4\n",
            "training =  0.8932, validation = 0.843\n",
            " epoch num = 5\n",
            "training =  0.906, validation = 0.839\n",
            " epoch num = 6\n",
            "training =  0.9212, validation = 0.82\n",
            " epoch num = 7\n",
            "training =  0.9244, validation = 0.821\n",
            " epoch num = 8\n",
            "training =  0.9296, validation = 0.824\n",
            " epoch num = 9\n",
            "training =  0.9268, validation = 0.824\n",
            "data perc = 0.6\n",
            " epoch num = 0\n",
            "training =  0.7596666666666667, validation = 0.852\n",
            " epoch num = 1\n",
            "training =  0.844, validation = 0.829\n",
            " epoch num = 2\n",
            "training =  0.8783333333333333, validation = 0.83\n",
            " epoch num = 3\n",
            "training =  0.8863333333333333, validation = 0.832\n",
            " epoch num = 4\n",
            "training =  0.889, validation = 0.845\n",
            " epoch num = 5\n",
            "training =  0.9053333333333333, validation = 0.856\n",
            " epoch num = 6\n",
            "training =  0.9066666666666666, validation = 0.833\n",
            " epoch num = 7\n",
            "training =  0.9243333333333333, validation = 0.835\n",
            " epoch num = 8\n",
            "training =  0.9253333333333333, validation = 0.846\n",
            " epoch num = 9\n",
            "training =  0.9303333333333333, validation = 0.848\n",
            "data perc = 0.7\n",
            " epoch num = 0\n",
            "training =  0.7617142857142857, validation = 0.811\n",
            " epoch num = 1\n",
            "training =  0.8517142857142858, validation = 0.856\n",
            " epoch num = 2\n",
            "training =  0.8754285714285714, validation = 0.848\n",
            " epoch num = 3\n",
            "training =  0.892, validation = 0.855\n",
            " epoch num = 4\n",
            "training =  0.9062857142857143, validation = 0.8\n",
            " epoch num = 5\n",
            "training =  0.9048571428571428, validation = 0.844\n",
            " epoch num = 6\n",
            "training =  0.9057142857142857, validation = 0.839\n",
            " epoch num = 7\n",
            "training =  0.9228571428571428, validation = 0.833\n",
            " epoch num = 8\n",
            "training =  0.9254285714285714, validation = 0.85\n",
            " epoch num = 9\n",
            "training =  0.9277142857142857, validation = 0.817\n",
            "data perc = 0.8\n",
            " epoch num = 0\n",
            "training =  0.77525, validation = 0.82\n",
            " epoch num = 1\n",
            "training =  0.846, validation = 0.791\n",
            " epoch num = 2\n",
            "training =  0.879, validation = 0.819\n",
            " epoch num = 3\n",
            "training =  0.89075, validation = 0.82\n",
            " epoch num = 4\n",
            "training =  0.89825, validation = 0.798\n",
            " epoch num = 5\n",
            "training =  0.90175, validation = 0.812\n",
            " epoch num = 6\n",
            "training =  0.914, validation = 0.835\n",
            " epoch num = 7\n",
            "training =  0.91475, validation = 0.844\n",
            " epoch num = 8\n",
            "training =  0.924, validation = 0.849\n",
            " epoch num = 9\n",
            "training =  0.9335, validation = 0.839\n",
            "data perc = 0.9\n",
            " epoch num = 0\n",
            "training =  0.7888888888888889, validation = 0.744\n",
            " epoch num = 1\n",
            "training =  0.8577777777777778, validation = 0.75\n",
            " epoch num = 2\n",
            "training =  0.8728888888888889, validation = 0.819\n",
            " epoch num = 3\n",
            "training =  0.8893333333333333, validation = 0.809\n",
            " epoch num = 4\n",
            "training =  0.8955555555555555, validation = 0.83\n",
            " epoch num = 5\n",
            "training =  0.8988888888888888, validation = 0.85\n",
            " epoch num = 6\n",
            "training =  0.9108888888888889, validation = 0.852\n",
            " epoch num = 7\n",
            "training =  0.9113333333333333, validation = 0.829\n",
            " epoch num = 8\n",
            "training =  0.9226666666666666, validation = 0.817\n",
            " epoch num = 9\n",
            "training =  0.9211111111111111, validation = 0.838\n",
            "data perc = 1.0\n",
            " epoch num = 0\n",
            "training =  0.792, validation = 0.836\n",
            " epoch num = 1\n",
            "training =  0.8636, validation = 0.817\n",
            " epoch num = 2\n",
            "training =  0.8742, validation = 0.848\n",
            " epoch num = 3\n",
            "training =  0.8844, validation = 0.84\n",
            " epoch num = 4\n",
            "training =  0.8936, validation = 0.834\n",
            " epoch num = 5\n",
            "training =  0.9116, validation = 0.851\n",
            " epoch num = 6\n",
            "training =  0.9136, validation = 0.859\n",
            " epoch num = 7\n",
            "training =  0.9188, validation = 0.822\n",
            " epoch num = 8\n",
            "training =  0.9144, validation = 0.831\n",
            " epoch num = 9\n",
            "training =  0.9194, validation = 0.84\n",
            "\n",
            "Part A Results exported to Charts and Graphs/\n",
            "\n",
            "Perceptron Classification Summary:\n",
            "        Training Accuracy  Validation Accuracy  Training Time\n",
            "Data %                                                       \n",
            "10.0               0.9140               0.7565         0.6771\n",
            "20.0               0.8882               0.7528         0.8063\n",
            "30.0               0.8796               0.7854         1.0610\n",
            "40.0               0.8780               0.8067         1.1376\n",
            "50.0               0.8832               0.8162         1.2547\n",
            "60.0               0.8849               0.8406         1.3688\n",
            "70.0               0.8874               0.8353         1.5449\n",
            "80.0               0.8877               0.8227         2.1328\n",
            "90.0               0.8869               0.8138         2.1579\n",
            "100.0              0.8886               0.8378         1.9488\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    perc = Perceptron()\n",
        "\n",
        "    #perc.run_percep_on_data(\"train\", \"face\")\n",
        "\n",
        "    perc.run_percep_on_data(\"train\", \"digit\")\n",
        "\n",
        "    #perc.perceptron_digits(\"train\")\n",
        "\n",
        "    #perc.perceptron_faces(\"train\")\n",
        "    \n",
        "    export_perceptron_results(perc.output, perc.training_times)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPOYpG/cG/Z5b84n0tbBB5U",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
